{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.131238Z",
     "iopub.status.idle": "2025-04-21T18:51:37.131434Z",
     "shell.execute_reply": "2025-04-21T18:51:37.131348Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.131340Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pendahuluan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.132395Z",
     "iopub.status.idle": "2025-04-21T18:51:37.132627Z",
     "shell.execute_reply": "2025-04-21T18:51:37.132520Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.132511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, re\n",
    "import warnings \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.133592Z",
     "iopub.status.idle": "2025-04-21T18:51:37.133876Z",
     "shell.execute_reply": "2025-04-21T18:51:37.133775Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.133763Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/gammax/train.csv').rename({'is_referenced': 'label'}, axis=1)\n",
    "test = pd.read_csv('/kaggle/input/gammax/test.csv')\n",
    "feature = pd.read_csv('/kaggle/input/gammax/papers_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.134766Z",
     "iopub.status.idle": "2025-04-21T18:51:37.135075Z",
     "shell.execute_reply": "2025-04-21T18:51:37.134914Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.134897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "feature.fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setelah kita periksa ternyata hanya , feature yang berbasis object / string yang hilang. Oleh karena itu , kita mengisi misisng value dengan `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.136050Z",
     "iopub.status.idle": "2025-04-21T18:51:37.136348Z",
     "shell.execute_reply": "2025-04-21T18:51:37.136210Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.136197Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4354 entries, 0 to 4353\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   paper_id          4354 non-null   object\n",
      " 1   doi               4354 non-null   object\n",
      " 2   title             4354 non-null   object\n",
      " 3   publication_year  4354 non-null   int64 \n",
      " 4   publication_date  4354 non-null   object\n",
      " 5   cited_by_count    4354 non-null   int64 \n",
      " 6   type              4354 non-null   object\n",
      " 7   authors           4354 non-null   object\n",
      " 8   concepts          4354 non-null   object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 306.3+ KB\n"
     ]
    }
   ],
   "source": [
    "def change_to_str(data):\n",
    "    columns_to_convert = ['doi', 'title', 'authors', 'concepts']\n",
    "    \n",
    "    for column in columns_to_convert:\n",
    "        data[column] = data[column].astype(str)\n",
    "    \n",
    "    return data\n",
    "\n",
    "feature = change_to_str(feature)\n",
    "feature.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Main Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe src=\"https://drive.google.com/file/d/1qHDvgQYFT2tkHvTBaKHtR7jxfRCEQO4-/preview\" width=\"640\" height=\"200\"></iframe>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Documents/Paper Representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.137802Z",
     "iopub.status.idle": "2025-04-21T18:51:37.138052Z",
     "shell.execute_reply": "2025-04-21T18:51:37.137946Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.137934Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import logging\n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback untuk ngeprint progress setiap epoch'''\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(f'Starting epoch {self.epoch}')\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(f'Finished epoch {self.epoch}')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.138796Z",
     "iopub.status.idle": "2025-04-21T18:51:37.139039Z",
     "shell.execute_reply": "2025-04-21T18:51:37.138930Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.138920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.fasttext import FastText\n",
    "import nltk\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "\n",
    "data_dir = \"/kaggle/input/gammax/Paper Database/Paper Database\"\n",
    "\n",
    "paper_texts = {}\n",
    "for fname in os.listdir(data_dir):\n",
    "    if fname.endswith(\".txt\"):\n",
    "        paper_id = fname.replace(\".txt\", \"\")\n",
    "        with open(os.path.join(data_dir, fname), 'r', encoding='utf-8') as f:\n",
    "            paper_texts[paper_id] = f.read().lower()  \n",
    "\n",
    "import nltk\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize_and_remove_stopwords(text):\n",
    "    tokens = simple_preprocess(text)\n",
    "    \n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "tagged_docs = [\n",
    "    TaggedDocument(words=tokenize_and_remove_stopwords(text), tags=[pid])\n",
    "    for pid, text in paper_texts.items()\n",
    "]\n",
    "\n",
    "\n",
    "modeldoc = Doc2Vec(vector_size=90, window=17, min_count=2, workers=8, epochs=25)\n",
    "modeldoc.build_vocab(tagged_docs)\n",
    "modeldoc.train(tagged_docs, total_examples=modeldoc.corpus_count, epochs=modeldoc.epochs, callbacks=[EpochLogger()])\n",
    "\n",
    "\n",
    "doc_vectors = {doc.tags[0]: modeldoc.dv[doc.tags[0]] for doc in tagged_docs}\n",
    "vectors_df = pd.DataFrame.from_dict(doc_vectors, orient='index')\n",
    "feature = feature.join(vectors_df, on='paper_id', how='left')\n",
    "\n",
    "print(\"Model Doc2Vec training selesai dan vektor telah disimpan di DataFrame!\")\n",
    "\n",
    "#Optional\n",
    "modeldoc.save(\"DOC2VWD20E20.model\")\n",
    "with open (\"DOC2VWD20E20.model\", \"rb\") as f:\n",
    "    modeldoc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perbandingan Doc2Vec dan BERT/Transformer-Based Models**\n",
    "\n",
    "Pada bagian ini, kita akan membandingkan **Doc2Vec** dengan model berbasis **BERT/Transformer** berdasarkan beberapa kelebihan yang dimiliki oleh Doc2Vec, serta bagaimana performa dan kelebihannya bila dibandingkan dengan BERT/Transformer.\n",
    "\n",
    "**1. Kelebihan Doc2Vec**\n",
    "\n",
    "- **Sangat Tidak Cost Sensitive**: Doc2Vec tidak memerlukan sumber daya komputasi yang besar dan relatif lebih murah dibandingkan model berbasis transformer seperti BERT.\n",
    "- **Tidak Memerlukan GPU**: Doc2Vec dapat dilatih dan dijalankan di CPU, membuatnya lebih mudah diakses dan diimplementasikan tanpa membutuhkan perangkat keras yang kuat.\n",
    "- **Cukup Cepat dan Representatif**: Dengan struktur yang lebih sederhana, Doc2Vec dapat menghasilkan representasi yang cepat dan cukup baik untuk banyak tugas pemrosesan bahasa alami.\n",
    "- **Tidak Terbatasi oleh Max Length**: Doc2Vec tidak memiliki batas panjang input seperti yang terdapat pada model berbasis Transformer, sehingga lebih fleksibel dalam menangani dokumen dengan panjang yang bervariasi.\n",
    "- **Memperhatikan Seluruh Isi Dokumen**: Doc2Vec membuat representasi vektor dari seluruh dokumen, memberikan gambaran umum dari teks tanpa kehilangan informasi konteks.\n",
    "\n",
    "**2. Kelebihan BERT/Transformer-Based Models**\n",
    "\n",
    "- **Lebih Akurat dalam Pemahaman Konteks**: BERT dapat memproses konteks kata secara bidirectional, memberikan pemahaman yang lebih baik terhadap teks dibandingkan Doc2Vec yang hanya mempertimbangkan urutan kata secara sekuensial.\n",
    "- **Menggunakan Pretrained Models**: BERT menawarkan model yang sudah dilatih dengan dataset besar, memungkinkan untuk aplikasi cepat dalam berbagai tugas NLP tanpa perlu pelatihan dari awal.\n",
    "- **Pemrosesan Teks yang Lebih Kompleks**: Transformer-based models dapat menangani teks yang lebih kompleks, seperti idiom, kalimat ambiguitas, dan konteks yang lebih dalam.\n",
    "- **Batasan Panjang Input**: Salah satu keterbatasan utama BERT dan model berbasis Transformer adalah **batas panjang input** yang terbatas, biasanya sekitar 512 token (pada BERT standar). Pada kasus yang melibatkan dokumen yang token-nya bisa lebih dari 4000, ini menjadi masalah besar, karena BERT dan model standar lainnya tidak dapat menangani input lebih panjang tanpa pemrosesan tambahan. Meskipun model seperti **BigBird** dan **Longformer** telah dikembangkan untuk mengatasi batas panjang ini dengan mekanisme sparse attention, mereka tetap memiliki batasan yang lebih kecil dibandingkan **Doc2Vec**, yang tidak terbatas oleh panjang dokumen.\n",
    "\n",
    "**3. Perbandingan Antara Doc2Vec dan BERT/Transformer-Based Models**\n",
    "\n",
    "| **Kriteria**                      | **Doc2Vec**                                | **BERT/Transformer-Based**                       |\n",
    "|------------------------------------|--------------------------------------------|-------------------------------------------------|\n",
    "| **Kebutuhan Sumber Daya**          | Tidak cost-sensitive, dapat berjalan di CPU ✅ | Memerlukan GPU dan sumber daya yang lebih besar  |\n",
    "| **Kecepatan Pelatihan**            | Cepat, lebih ringan dalam pelatihan ✅        | Relatif lebih lambat karena model yang lebih besar |\n",
    "| **Kebutuhan GPU**                  | Tidak memerlukan GPU  ✅                      | Memerlukan GPU untuk pelatihan dan inferensi    |\n",
    "| **Akurasi dalam Pemahaman Konteks**| Cukup baik, berdasarkan urutan kata       | Sangat akurat dengan konteks bidirectional  ✅    |\n",
    "| **Fleksibilitas Panjang Dokumen**  | Tidak terbatas oleh panjang teks ✅          | Tergantung pada panjang input yang dapat diproses (biasanya ada batasan, seperti 512 token) |\n",
    "| **Pretraining**                    | Tidak menggunakan model pretrained ✅        | Menggunakan model pretrained dengan dataset besar |\n",
    "| **Representasi Dokumen**           | Mewakili seluruh dokumen dalam satu vektor ✅ | Memiliki representasi yang lebih rinci untuk setiap kata dalam konteks |\n",
    "| **Penggunaan Sumber Daya**         | Lebih efisien dalam hal memori dan komputasi ✅ | Membutuhkan memori yang besar dan daya komputasi tinggi |\n",
    "| **Cocok untuk Dokumen Panjang**    | Sangat cocok, karena tidak terbatas oleh panjang token ✅| Terbatas dengan panjang teks (misalnya 512 token untuk BERT standar), meskipun BigBird/Longformer memiliki batas yang lebih tinggi namun masih terbatas dibandingkan Doc2Vec |\n",
    "\n",
    "**4. Kesimpulan**\n",
    "\n",
    "- **`Doc2Vec`** adalah pilihan yang sangat baik jika  membutuhkan model yang cepat, tidak memerlukan sumber daya besar, dan dapat menangani dokumen panjang dengan fleksibel. Oleh karena itu , kita menggunakan Doc2Vec\n",
    "- **BERT/Transformer-Based** models lebih cocok jika membutuhkan pemahaman yang lebih mendalam terhadap konteks dan memiliki sumber daya komputasi yang cukup besar. Namun, model-model ini memiliki keterbatasan terkait panjang input, yang menjadi masalah jika dokumen sangat panjang (lebih dari 4000 token). Walaupun model seperti **BigBird** dan **Longformer** menawarkan solusi dengan kapasitas panjang lebih besar, mereka masih tidak bisa mengalahkan fleksibilitas Doc2Vec dalam menangani dokumen yang sangat panjang tanpa batasan yang ketat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Metadata Representation (`Title`, `Concepts`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A.) Title Representation (Fast Text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.141104Z",
     "iopub.status.idle": "2025-04-21T18:51:37.141400Z",
     "shell.execute_reply": "2025-04-21T18:51:37.141261Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.141248Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TITLE] Epoch 1/15 endrt\n",
      "[TITLE] Epoch 2/15 endrt\n",
      "[TITLE] Epoch 3/15 endrt\n",
      "[TITLE] Epoch 4/15 endrt\n",
      "[TITLE] Epoch 5/15 endrt\n",
      "[TITLE] Epoch 6/15 endrt\n",
      "[TITLE] Epoch 7/15 endrt\n",
      "[TITLE] Epoch 8/15 endrt\n",
      "[TITLE] Epoch 9/15 endrt\n",
      "[TITLE] Epoch 10/15 endrt\n",
      "[TITLE] Epoch 11/15 endrt\n",
      "[TITLE] Epoch 12/15 endrt\n",
      "[TITLE] Epoch 13/15 endrt\n",
      "[TITLE] Epoch 14/15 endrt\n",
      "[TITLE] Epoch 15/15 endrt\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "tokenized_titles = [title.lower().split() for title in feature['title']]\n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self, total_epochs):\n",
    "        self.epoch = 0\n",
    "        self.total_epochs = total_epochs\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(f\"[TITLE] Epoch {self.epoch + 1}/{self.total_epochs} start\", end='\\r')\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(f\"[TITLE] Epoch {self.epoch + 1}/{self.total_epochs} end\")\n",
    "        self.epoch += 1\n",
    "\n",
    "total_epochs = 15\n",
    "modeltitle_ft = FastText(vector_size=5, window=2, min_count=1, workers=8, epochs=total_epochs, seed=42)\n",
    "\n",
    "modeltitle_ft.build_vocab(corpus_iterable=tokenized_titles)\n",
    "modeltitle_ft.train(corpus_iterable=tokenized_titles, total_examples=len(tokenized_titles), epochs=modeltitle_ft.epochs, callbacks=[EpochLogger(total_epochs)])\n",
    "\n",
    "#modeltitle_ft.save(\"modeltitle_ft.model\") #Optional\n",
    "\n",
    "title_vectors_ft = []\n",
    "for title in tokenized_titles:\n",
    "    word_vectors = [modeltitle_ft.wv[word] for word in title if word in modeltitle_ft.wv]\n",
    "    if word_vectors:\n",
    "        title_vectors_ft.append(sum(word_vectors) / len(word_vectors))\n",
    "    else:\n",
    "        title_vectors_ft.append([0] * 10)\n",
    "\n",
    "title_df_ft = pd.DataFrame(title_vectors_ft, columns=[f'ft_title_{i}' for i in range(5)])\n",
    "\n",
    "# Gabungkan ke feature\n",
    "feature = pd.concat([feature.reset_index(drop=True), title_df_ft], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B.) Title Representation (BERT `(AllenAi-SPECTER)`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 18:26:36.858051: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745432796.880661    1736 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745432796.887476    1736 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Encoding titles with SPECTER: 100%|██████████| 4354/4354 [00:32<00:00, 133.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/specter\")\n",
    "model = AutoModel.from_pretrained(\"allenai/specter\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "title_dfz = feature[['paper_id', 'title']].copy()\n",
    "\n",
    "def get_specter_embedding(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()  \n",
    "\n",
    "\n",
    "tqdm.pandas(desc=\"Encoding titles with SPECTER\")\n",
    "title_dfz['title_vector'] = title_dfz['title'].progress_apply(get_specter_embedding)\n",
    "\n",
    "vector_df = pd.DataFrame(title_dfz['title_vector'].to_list(), columns=[f'specter_title_{i}' for i in range(title_dfz['title_vector'][0].shape[0])])\n",
    "\n",
    "title_dfz = pd.concat([title_dfz.drop(columns=['title_vector']), vector_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam notebook ini, kita akan meng-extract representasi judul artikel menggunakan dua metode berbeda: **`FastText`** dan **`SPECTER`**. Keduanya dipilih karena biaya komputasi yang relatif rendah, namun masing-masing memiliki keunggulan yang dapat dioptimalkan tergantung pada kebutuhan aplikasi.\n",
    "\n",
    "**1. Mengapa Menggunakan FastText dan SPECTER?**\n",
    "\n",
    "- **`FastText`** dari Gensim adalah model yang **`ringan dan efisien`** dalam menghasilkan representasi kata. Ini sangat cocok untuk tugas-tugas yang membutuhkan penggunaan sumber daya komputasi yang rendah, seperti ketika bekerja dengan dataset yang besar atau terbatasnya sumber daya komputasi.\n",
    "  \n",
    "- **`SPECTER`** adalah model berbasis BERT yang telah dioptimalkan untuk **`teks akademik`**. Meskipun berbasis arsitektur transformer, SPECTER lebih efisien dibandingkan BERT asli karena sudah di-tune untuk tugas yang lebih spesifik, sehingga lebih hemat dalam penggunaan sumber daya komputasi tanpa mengorbankan kualitas representasi.\n",
    "\n",
    "**2. Keunggulan Menggunakan FastText dan SPECTER**\n",
    "\n",
    "**`FastText`**\n",
    "- **Fleksibilitas**: FastText dapat menangani kata yang tidak ditemukan dalam kamus (out-of-vocabulary words) dengan membaginya menjadi sub-kata.\n",
    "- **Ringan**: Dapat dijalankan dengan sumber daya komputasi yang terbatas, seperti di CPU biasa, tanpa membutuhkan GPU.\n",
    "- **Tidak Terbatas pada Panjang Input**: FastText tidak terikat pada panjang input, sehingga sangat cocok untuk data teks yang bervariasi panjangnya.\n",
    "\n",
    "**`SPECTER`**\n",
    "- **Diperuntukkan untuk Teks Akademik**: SPECTER telah dioptimalkan untuk menangani teks akademik, sehingga menghasilkan representasi yang lebih relevan dan mendalam untuk judul-judul penelitian.\n",
    "- **Efisiensi**: Meskipun menggunakan arsitektur berbasis transformer, SPECTER telah di-tune untuk tugas akademik, menjadikannya lebih efisien dibandingkan model transformer lainnya seperti BERT.\n",
    "- **Representasi yang Lebih Kuat**: SPECTER memberikan representasi yang lebih dalam dan kaya untuk teks akademik, berfokus pada konteks dan makna dari judul artikel.\n",
    "\n",
    "**3. Ekstraksi Representasi dengan FastText dan SPECTER**\n",
    "\n",
    "Kedua model ini akan digunakan untuk mengekstrak representasi dari judul artikel di dataset kita. Keunggulan utamanya adalah biaya komputasi yang rendah serta kemampuannya untuk menghasilkan representasi yang cukup akurat untuk aplikasi teks berbasis judul artikel.\n",
    "\n",
    "- **`FastText`**: Kita akan menggunakan FastText untuk mendapatkan representasi kata dari setiap judul dengan cara rata-rata vektor kata yang ada di dalam judul tersebut.\n",
    "- **`SPECTER`**: Kita juga akan menggunakan SPECTER untuk menghasilkan representasi berbasis transformer yang lebih mendalam, dengan keuntungan menggunakan model pretrained yang sudah dioptimalkan.\n",
    "\n",
    "Langkah-Langkah Ekstraksi:\n",
    "\n",
    "**`FastText`**: \n",
    "   - Tokenisasi judul artikel.\n",
    "   - Latih model FastText pada tokenized data.\n",
    "   - Ekstrak representasi rata-rata untuk setiap judul berdasarkan vektor kata yang dihasilkan oleh FastText.\n",
    "\n",
    "**`SPECTER`**:\n",
    "   - Tokenisasi judul artikel.\n",
    "   - Gunakan model pretrained SPECTER untuk mengonversi judul menjadi vektor representasi.\n",
    "   - SPECTER akan memberikan representasi yang lebih kaya dengan menggunakan arsitektur berbasis BERT.\n",
    "\n",
    "\n",
    "**4. Perbandingan Proses Ekstraksi**\n",
    "\n",
    "| **Metode**      | **Sumber Daya yang Dibutuhkan**      | **Kelebihan**                                      |\n",
    "|-----------------|-------------------------------------|---------------------------------------------------|\n",
    "| **FastText**    | CPU atau GPU                       | Ringan, dapat digunakan di berbagai perangkat keras, tidak terbatas panjang input. |\n",
    "| **SPECTER**     | Memerlukan GPU untuk inferensi     | Representasi lebih kuat untuk teks akademik, efisien meskipun berbasis transformer. |\n",
    "\n",
    "**5. Kesimpulan**\n",
    "\n",
    "Kedua model **FastText** dan **SPECTER** sangat cocok untuk ekstraksi representasi judul artikel dengan biaya komputasi rendah. Meskipun FastText lebih cepat dan tidak membutuhkan GPU, SPECTER memberikan representasi yang lebih mendalam dan cocok untuk teks akademik.\n",
    "\n",
    "Kedua model ini bisa digunakan secara bersamaan, mengingat keduanya memiliki **biaya komputasi rendah**, namun memberikan hasil yang cukup baik dalam konteks representasi judul artikel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C.) Concepts Representation (Fast Text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.142729Z",
     "iopub.status.idle": "2025-04-21T18:51:37.143038Z",
     "shell.execute_reply": "2025-04-21T18:51:37.142898Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.142884Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONCEPTS] Epoch 1/15 endrt\n",
      "[CONCEPTS] Epoch 2/15 endrt\n",
      "[CONCEPTS] Epoch 3/15 endrt\n",
      "[CONCEPTS] Epoch 4/15 endrt\n",
      "[CONCEPTS] Epoch 5/15 endrt\n",
      "[CONCEPTS] Epoch 6/15 endrt\n",
      "[CONCEPTS] Epoch 7/15 endrt\n",
      "[CONCEPTS] Epoch 8/15 endrt\n",
      "[CONCEPTS] Epoch 9/15 endrt\n",
      "[CONCEPTS] Epoch 10/15 endrt\n",
      "[CONCEPTS] Epoch 11/15 endrt\n",
      "[CONCEPTS] Epoch 12/15 endrt\n",
      "[CONCEPTS] Epoch 13/15 endrt\n",
      "[CONCEPTS] Epoch 14/15 endrt\n",
      "[CONCEPTS] Epoch 15/15 endrt\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "import pandas as pd\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "tokenized_concepts = [\n",
    "    [c.strip().lower().replace(\" \", \"_\") for c in concepts.split(\";\") if c.strip()]\n",
    "    for concepts in feature['concepts']\n",
    "]\n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self, total_epochs):\n",
    "        self.epoch = 0\n",
    "        self.total_epochs = total_epochs\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(f\"[CONCEPTS] Epoch {self.epoch + 1}/{self.total_epochs} start\", end='\\r')\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(f\"[CONCEPTS] Epoch {self.epoch + 1}/{self.total_epochs} end\")\n",
    "        self.epoch += 1\n",
    "\n",
    "\n",
    "total_epochs = 15\n",
    "modelconcept_ft = FastText(vector_size=5, window=2, min_count=1, workers=8, epochs=total_epochs, seed=42)\n",
    "\n",
    "modelconcept_ft.build_vocab(corpus_iterable=tokenized_concepts)\n",
    "modelconcept_ft.train(corpus_iterable=tokenized_concepts, total_examples=len(tokenized_concepts), epochs=modelconcept_ft.epochs, callbacks=[EpochLogger(total_epochs)])\n",
    "\n",
    "# modelconcept_ft.save(\"modelconcept_ft.model\") #Optional\n",
    "\n",
    "concept_vectors_ft = []\n",
    "for concept_list in tokenized_concepts:\n",
    "    word_vectors = [modelconcept_ft.wv[word] for word in concept_list if word in modelconcept_ft.wv]\n",
    "    if word_vectors:\n",
    "        concept_vectors_ft.append(sum(word_vectors) / len(word_vectors))\n",
    "    else:\n",
    "        concept_vectors_ft.append([0] * 20)\n",
    "\n",
    "concept_df_ft = pd.DataFrame(concept_vectors_ft, columns=[f'ft_concept_{i}' for i in range(5)])\n",
    "feature = pd.concat([feature.reset_index(drop=True), concept_df_ft], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **D.) Concepts Representation  (BERT `(AllenAi-SPECTER)`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/specter\")\n",
    "model = AutoModel.from_pretrained(\"allenai/specter\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "concept_dfz = feature[['paper_id', 'concepts']].copy()\n",
    "\n",
    "def get_specter_embedding(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()  \n",
    "\n",
    "tqdm.pandas(desc=\"Encoding cocncepts with SPECTER\")\n",
    "concept_dfz['concepts_vector'] = concept_dfz['concepts'].progress_apply(get_specter_embedding)\n",
    "\n",
    "vector_df = pd.DataFrame(concept_dfz['concepts_vector'].to_list(), columns=[f'specter_concepts_title_{i}' for i in range(concept_dfz['concepts_vector'][0].shape[0])])\n",
    "\n",
    "concept_dfz = pd.concat([concept_dfz.drop(columns=['concepts_vector']), vector_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam notebook ini, kita juga akan meng-extract representasi **konsep** menggunakan dua metode berbeda: **FastText** dan **SPECTER**. Keduanya dipilih karena biaya komputasi yang rendah, namun masing-masing memiliki keunggulan yang dapat dioptimalkan tergantung pada kebutuhan aplikasi.\n",
    "\n",
    "**1. Mengapa Menggunakan FastText dan SPECTER?**\n",
    "\n",
    "- **`FastText`** dari Gensim adalah model yang `ringan dan efisien` dalam menghasilkan representasi kata. Ini sangat cocok untuk tugas-tugas yang membutuhkan penggunaan sumber daya komputasi yang rendah, seperti ketika bekerja dengan dataset yang besar atau terbatasnya sumber daya komputasi.\n",
    "  \n",
    "- **`SPECTER`** adalah model berbasis BERT yang telah dioptimalkan untuk `teks akademik`. Meskipun berbasis arsitektur transformer, SPECTER lebih efisien dibandingkan BERT asli karena sudah di-tune untuk tugas yang lebih spesifik, sehingga lebih hemat dalam penggunaan sumber daya komputasi tanpa mengorbankan kualitas representasi.\n",
    "\n",
    "**2. Keunggulan Menggunakan FastText dan SPECTER**\n",
    "\n",
    "**`FastText`**\n",
    "- **Fleksibilitas**: FastText dapat menangani kata yang tidak ditemukan dalam kamus (out-of-vocabulary words) dengan membaginya menjadi sub-kata.\n",
    "- **Ringan**: Dapat dijalankan dengan sumber daya komputasi yang terbatas, seperti di CPU biasa, tanpa membutuhkan GPU.\n",
    "- **Tidak Terbatas pada Panjang Input**: FastText tidak terikat pada panjang input, sehingga sangat cocok untuk data teks yang bervariasi panjangnya.\n",
    "\n",
    "**`SPECTER`**\n",
    "- **Diperuntukkan untuk Teks Akademik**: SPECTER telah dioptimalkan untuk menangani teks akademik, sehingga menghasilkan representasi yang lebih relevan dan mendalam untuk **konsep**-konsep dalam konteks penelitian.\n",
    "- **Efisiensi**: Meskipun menggunakan arsitektur berbasis transformer, SPECTER telah di-tune untuk tugas akademik, menjadikannya lebih efisien dibandingkan model transformer lainnya seperti BERT.\n",
    "- **Representasi yang Lebih Kuat**: SPECTER memberikan representasi yang lebih dalam dan kaya untuk **konsep** akademik, berfokus pada konteks dan makna dari **konsep**-konsep yang disarankan dalam metadata.\n",
    "\n",
    "**3. Mengapa Menggunakan FastText dan SPECTER untuk **Konsep**?**\n",
    "\n",
    "Dalam konteks ini, **konsep** yang dimaksud sering kali lebih ringkas dan terfokus pada poin-poin utama yang ditemukan dalam metadata, yang sudah diringkas dan tidak terlalu panjang. Oleh karena itu, baik **FastText** maupun **SPECTER** sangat cocok digunakan untuk mengekstrak representasi dari **konsep**-konsep tersebut. \n",
    "\n",
    "- **`FastText`**: Model ini sangat efisien untuk mengekstrak representasi dari **konsep** yang lebih pendek dan sering kali mencakup kata-kata yang tidak ada dalam kamus.\n",
    "- **`SPECTER`**: Dengan optimisasi untuk teks akademik, SPECTER mampu memberikan representasi yang lebih kaya dan relevan untuk **konsep** yang terdapat dalam metadata yang terstruktur dan lebih ringkas.\n",
    "\n",
    "**4. Ekstraksi Representasi dengan FastText dan SPECTER**\n",
    "\n",
    "Kedua model ini akan digunakan untuk mengekstrak representasi dari **konsep** yang ada dalam dataset kita. Keunggulan utamanya adalah biaya komputasi yang rendah serta kemampuannya untuk menghasilkan representasi yang cukup akurat untuk aplikasi berbasis **konsep**-konsep metadata.\n",
    "\n",
    "- **`FastText`**: Kita akan menggunakan FastText untuk mendapatkan representasi kata dari setiap **konsep** dengan cara rata-rata vektor kata yang ada di dalam **konsep** tersebut.\n",
    "- **`SPECTER`**: Kita juga akan menggunakan SPECTER untuk menghasilkan representasi berbasis transformer yang lebih mendalam, dengan keuntungan menggunakan model pretrained yang sudah dioptimalkan.\n",
    "\n",
    "Langkah-Langkah Ekstraksi:\n",
    "\n",
    "**`FastText`**: \n",
    "   - Tokenisasi **konsep**.\n",
    "   - Latih model FastText pada tokenized data.\n",
    "   - Ekstrak representasi rata-rata untuk setiap **konsep** berdasarkan vektor kata yang dihasilkan oleh FastText.\n",
    "\n",
    "**`SPECTER`**:\n",
    "   - Tokenisasi **konsep**.\n",
    "   - Gunakan model pretrained SPECTER untuk mengonversi **konsep** menjadi vektor representasi.\n",
    "   - SPECTER akan memberikan representasi yang lebih kaya dengan menggunakan arsitektur berbasis BERT.\n",
    "\n",
    "**5. Perbandingan Proses Ekstraksi**\n",
    "\n",
    "| **Metode**      | **Sumber Daya yang Dibutuhkan**      | **Kelebihan**                                      |\n",
    "|-----------------|-------------------------------------|---------------------------------------------------|\n",
    "| **FastText**    | CPU atau GPU                       | Ringan, dapat digunakan di berbagai perangkat keras, tidak terbatas panjang input. |\n",
    "| **SPECTER**     | Memerlukan GPU untuk inferensi     | Representasi lebih kuat untuk **konsep** akademik, efisien meskipun berbasis transformer. |\n",
    "\n",
    "**6. Kesimpulan**\n",
    "\n",
    "Kedua model **FastText** dan **SPECTER** sangat cocok untuk ekstraksi representasi **konsep** dengan biaya komputasi rendah. Meskipun FastText lebih cepat dan tidak membutuhkan GPU, SPECTER memberikan representasi yang lebih mendalam dan cocok untuk **konsep** akademik.\n",
    "\n",
    "Kedua model ini bisa digunakan secara bersamaan, mengingat keduanya memiliki **biaya komputasi rendah**, namun memberikan hasil yang cukup baik dalam konteks representasi **konsep** metadata.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Metadata Representation (Non Text)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A.) Date Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.144197Z",
     "iopub.status.idle": "2025-04-21T18:51:37.144496Z",
     "shell.execute_reply": "2025-04-21T18:51:37.144356Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.144342Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def to_date_time(data):\n",
    "    data['publication_date'] = pd.to_datetime(data['publication_date'], errors='coerce')\n",
    "\n",
    "    mask_na_date = data['publication_date'].isna()\n",
    "    mask_valid_year = pd.notna(data['publication_year'])\n",
    "    data.loc[mask_na_date & mask_valid_year, 'publication_date'] = pd.to_datetime(\n",
    "        '01/01/' + data.loc[mask_na_date & mask_valid_year, 'publication_year'].astype(str),\n",
    "        format='%d/%m/%Y',\n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "    data['month'] = data['publication_date'].dt.month.fillna(0).astype(int)\n",
    "    data['day'] = data['publication_date'].dt.day.fillna(0).astype(int)\n",
    "\n",
    "    return data\n",
    "\n",
    "feature = to_date_time(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya , akan di ekstraksi waktu yaitu mengubah tanggal publikasi menjadi date time untuk menambah fitur yang representatif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B.) Authors Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.145489Z",
     "iopub.status.idle": "2025-04-21T18:51:37.145821Z",
     "shell.execute_reply": "2025-04-21T18:51:37.145674Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.145659Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_primary_author(authors_series):\n",
    "    primary_authors = authors_series.apply(lambda x: x.split(';')[0].strip() if isinstance(x, str) and ';' in x else (x.strip() if isinstance(x, str) else None))\n",
    "    return primary_authors\n",
    "\n",
    "def count_primary_author_occurrences(dataframe, authors_column='authors', new_column_name='primary_author_count'):\n",
    "    primary_authors = get_primary_author(dataframe[authors_column])\n",
    "    author_counts = primary_authors.value_counts().to_dict()\n",
    "    dataframe[new_column_name] = primary_authors.map(author_counts).fillna(0).astype(int)\n",
    "    return dataframe\n",
    "\n",
    "feature['primary_author'] = get_primary_author(feature['authors'])\n",
    "feature = count_primary_author_occurrences(feature, authors_column='authors', new_column_name='primary_author_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada bagian ini kita hanya mengekstraksi pemilik (Nama Author) , dari jurnal. Fitur ini diharpakan juga dapat memberikan representasi yang cukup baik untuk prediksi nantinya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C.) Journal Name (DOI) Feature Engineering (Optional)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.146990Z",
     "iopub.status.idle": "2025-04-21T18:51:37.147299Z",
     "shell.execute_reply": "2025-04-21T18:51:37.147168Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.147155Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Journal Names: 100%|██████████| 4354/4354 [00:00<00:00, 171987.72it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_journal_name(doi_url):\n",
    "    \"\"\"\n",
    "    Mengekstrak nama website/tempat jurnal dari URL DOI.\n",
    "\n",
    "    Args:\n",
    "        doi_url (str): URL DOI.\n",
    "\n",
    "    Returns:\n",
    "        str or None: Nama website/tempat jurnal atau None jika tidak dapat diekstrak.\n",
    "    \"\"\"\n",
    "    if isinstance(doi_url, str) and doi_url.startswith(\"https://doi.org/\"):\n",
    "        try:\n",
    "            parsed_url = urlparse(doi_url)\n",
    "            path_segments = parsed_url.path.split('/')\n",
    "            if len(path_segments) > 2:\n",
    "                potential_name = path_segments[2].split('.')[0]\n",
    "                return potential_name\n",
    "            else:\n",
    "                match = re.search(r\"doi\\.org\\/10\\.\\d+\\/([a-zA-Z0-9-]+)\", doi_url)\n",
    "                if match:\n",
    "                    return match.group(1).split('.')[0]\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def create_journal_name_column_with_tqdm(dataframe, doi_column='doi', new_column_name='journal_name'):\n",
    "    \"\"\"\n",
    "    Membuat kolom baru di DataFrame yang berisi nama website/tempat jurnal dari kolom DOI, dengan menggunakan tqdm.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame yang berisi kolom DOI.\n",
    "        doi_column (str): Nama kolom yang berisi URL DOI (default: 'doi').\n",
    "        new_column_name (str): Nama kolom baru untuk menyimpan nama jurnal (default: 'journal_name').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame dengan kolom baru yang berisi nama jurnal.\n",
    "    \"\"\"\n",
    "    journal_names = []\n",
    "    for doi in tqdm(dataframe[doi_column], desc=\"Extracting Journal Names\"):\n",
    "        journal_names.append(extract_journal_name(doi))\n",
    "    dataframe[new_column_name] = journal_names\n",
    "    return dataframe\n",
    "\n",
    "feature = create_journal_name_column_with_tqdm(feature)\n",
    "feature['total_cited_by_count_per_site'] = feature.groupby(['journal_name', 'publication_year'])['cited_by_count'].transform('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pada notebook ini, kita menjelaskan fungsi untuk mengekstrak nama jurnal dari URL DOI dan implementasinya untuk menambah kolom baru pada DataFrame, yang kemudian digunakan untuk analisis lebih lanjut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Data Preparation for Training (Feature Engineering for Paper and References)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A.) Feature Extraction to Train Dataset (Merge Metadata Representation and Document Representation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.148912Z",
     "iopub.status.idle": "2025-04-21T18:51:37.149233Z",
     "shell.execute_reply": "2025-04-21T18:51:37.149085Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.149070Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper</th>\n",
       "      <th>referenced_paper</th>\n",
       "      <th>label</th>\n",
       "      <th>publication_year_paper</th>\n",
       "      <th>cited_by_count_paper</th>\n",
       "      <th>0_paper</th>\n",
       "      <th>1_paper</th>\n",
       "      <th>2_paper</th>\n",
       "      <th>3_paper</th>\n",
       "      <th>4_paper</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_concept_0_ref</th>\n",
       "      <th>ft_concept_1_ref</th>\n",
       "      <th>ft_concept_2_ref</th>\n",
       "      <th>ft_concept_3_ref</th>\n",
       "      <th>ft_concept_4_ref</th>\n",
       "      <th>month_ref</th>\n",
       "      <th>day_ref</th>\n",
       "      <th>primary_author_count_ref</th>\n",
       "      <th>total_cited_by_count_per_site_ref</th>\n",
       "      <th>paper_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2128</td>\n",
       "      <td>p3728</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>357</td>\n",
       "      <td>0.133807</td>\n",
       "      <td>2.425045</td>\n",
       "      <td>3.516026</td>\n",
       "      <td>2.628832</td>\n",
       "      <td>5.929857</td>\n",
       "      <td>...</td>\n",
       "      <td>2.152482</td>\n",
       "      <td>-0.243626</td>\n",
       "      <td>1.459940</td>\n",
       "      <td>2.166929</td>\n",
       "      <td>-2.127061</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2492.000000</td>\n",
       "      <td>p3728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0389</td>\n",
       "      <td>p3811</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>981</td>\n",
       "      <td>-3.783838</td>\n",
       "      <td>-6.096706</td>\n",
       "      <td>-0.857891</td>\n",
       "      <td>5.968105</td>\n",
       "      <td>-5.302592</td>\n",
       "      <td>...</td>\n",
       "      <td>1.941954</td>\n",
       "      <td>-0.295563</td>\n",
       "      <td>1.304326</td>\n",
       "      <td>1.991976</td>\n",
       "      <td>-1.884434</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1169.811321</td>\n",
       "      <td>p3811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p1298</td>\n",
       "      <td>p3760</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>16255</td>\n",
       "      <td>0.971798</td>\n",
       "      <td>-0.765241</td>\n",
       "      <td>-4.719200</td>\n",
       "      <td>4.295119</td>\n",
       "      <td>-0.852547</td>\n",
       "      <td>...</td>\n",
       "      <td>1.622277</td>\n",
       "      <td>0.012452</td>\n",
       "      <td>1.674822</td>\n",
       "      <td>1.605003</td>\n",
       "      <td>-1.850415</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>p3760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0211</td>\n",
       "      <td>p1808</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>18641</td>\n",
       "      <td>3.377248</td>\n",
       "      <td>-1.904573</td>\n",
       "      <td>-2.885740</td>\n",
       "      <td>2.813201</td>\n",
       "      <td>0.593965</td>\n",
       "      <td>...</td>\n",
       "      <td>1.216073</td>\n",
       "      <td>-0.081154</td>\n",
       "      <td>1.038677</td>\n",
       "      <td>1.160670</td>\n",
       "      <td>-1.270961</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1479.000000</td>\n",
       "      <td>p1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0843</td>\n",
       "      <td>p2964</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>799</td>\n",
       "      <td>-6.031777</td>\n",
       "      <td>-2.581627</td>\n",
       "      <td>2.441402</td>\n",
       "      <td>-0.522494</td>\n",
       "      <td>-2.939475</td>\n",
       "      <td>...</td>\n",
       "      <td>1.535607</td>\n",
       "      <td>0.205591</td>\n",
       "      <td>1.784222</td>\n",
       "      <td>1.353299</td>\n",
       "      <td>-1.898473</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>645.000000</td>\n",
       "      <td>p2964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410686</th>\n",
       "      <td>p3478</td>\n",
       "      <td>p2966</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>1056</td>\n",
       "      <td>-0.365042</td>\n",
       "      <td>-9.563304</td>\n",
       "      <td>1.368957</td>\n",
       "      <td>-1.045948</td>\n",
       "      <td>5.600297</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264230</td>\n",
       "      <td>-0.392865</td>\n",
       "      <td>1.465489</td>\n",
       "      <td>2.273584</td>\n",
       "      <td>-2.102016</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>p2966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410687</th>\n",
       "      <td>p0719</td>\n",
       "      <td>p2382</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1438</td>\n",
       "      <td>9.921428</td>\n",
       "      <td>2.813704</td>\n",
       "      <td>4.166034</td>\n",
       "      <td>5.341912</td>\n",
       "      <td>0.405513</td>\n",
       "      <td>...</td>\n",
       "      <td>1.676756</td>\n",
       "      <td>0.686651</td>\n",
       "      <td>2.834742</td>\n",
       "      <td>1.086740</td>\n",
       "      <td>-2.547796</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>p2382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410688</th>\n",
       "      <td>p1805</td>\n",
       "      <td>p3209</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2088</td>\n",
       "      <td>6.445601</td>\n",
       "      <td>-1.094483</td>\n",
       "      <td>-2.229727</td>\n",
       "      <td>1.385319</td>\n",
       "      <td>6.413883</td>\n",
       "      <td>...</td>\n",
       "      <td>1.754729</td>\n",
       "      <td>-0.051348</td>\n",
       "      <td>1.553547</td>\n",
       "      <td>1.709094</td>\n",
       "      <td>-1.839340</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>806.272727</td>\n",
       "      <td>p3209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410689</th>\n",
       "      <td>p4213</td>\n",
       "      <td>p0457</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>707</td>\n",
       "      <td>2.058993</td>\n",
       "      <td>0.765467</td>\n",
       "      <td>4.445077</td>\n",
       "      <td>1.538046</td>\n",
       "      <td>3.039839</td>\n",
       "      <td>...</td>\n",
       "      <td>1.855709</td>\n",
       "      <td>-0.208949</td>\n",
       "      <td>1.330966</td>\n",
       "      <td>1.797521</td>\n",
       "      <td>-1.804249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>806.272727</td>\n",
       "      <td>p0457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410690</th>\n",
       "      <td>p0203</td>\n",
       "      <td>p1051</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>2277</td>\n",
       "      <td>0.351118</td>\n",
       "      <td>-4.022318</td>\n",
       "      <td>3.720409</td>\n",
       "      <td>2.376196</td>\n",
       "      <td>-1.567403</td>\n",
       "      <td>...</td>\n",
       "      <td>1.840279</td>\n",
       "      <td>0.185687</td>\n",
       "      <td>1.885126</td>\n",
       "      <td>1.558938</td>\n",
       "      <td>-2.204442</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>p1051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410691 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        paper referenced_paper  label  publication_year_paper  \\\n",
       "0       p2128            p3728      0                    2021   \n",
       "1       p0389            p3811      0                    1995   \n",
       "2       p1298            p3760      0                    2017   \n",
       "3       p0211            p1808      0                    2017   \n",
       "4       p0843            p2964      0                    2022   \n",
       "...       ...              ...    ...                     ...   \n",
       "410686  p3478            p2966      0                    1996   \n",
       "410687  p0719            p2382      1                    2017   \n",
       "410688  p1805            p3209      0                    2015   \n",
       "410689  p4213            p0457      0                    2020   \n",
       "410690  p0203            p1051      0                    2020   \n",
       "\n",
       "        cited_by_count_paper   0_paper   1_paper   2_paper   3_paper  \\\n",
       "0                        357  0.133807  2.425045  3.516026  2.628832   \n",
       "1                        981 -3.783838 -6.096706 -0.857891  5.968105   \n",
       "2                      16255  0.971798 -0.765241 -4.719200  4.295119   \n",
       "3                      18641  3.377248 -1.904573 -2.885740  2.813201   \n",
       "4                        799 -6.031777 -2.581627  2.441402 -0.522494   \n",
       "...                      ...       ...       ...       ...       ...   \n",
       "410686                  1056 -0.365042 -9.563304  1.368957 -1.045948   \n",
       "410687                  1438  9.921428  2.813704  4.166034  5.341912   \n",
       "410688                  2088  6.445601 -1.094483 -2.229727  1.385319   \n",
       "410689                   707  2.058993  0.765467  4.445077  1.538046   \n",
       "410690                  2277  0.351118 -4.022318  3.720409  2.376196   \n",
       "\n",
       "         4_paper  ...  ft_concept_0_ref  ft_concept_1_ref  ft_concept_2_ref  \\\n",
       "0       5.929857  ...          2.152482         -0.243626          1.459940   \n",
       "1      -5.302592  ...          1.941954         -0.295563          1.304326   \n",
       "2      -0.852547  ...          1.622277          0.012452          1.674822   \n",
       "3       0.593965  ...          1.216073         -0.081154          1.038677   \n",
       "4      -2.939475  ...          1.535607          0.205591          1.784222   \n",
       "...          ...  ...               ...               ...               ...   \n",
       "410686  5.600297  ...          2.264230         -0.392865          1.465489   \n",
       "410687  0.405513  ...          1.676756          0.686651          2.834742   \n",
       "410688  6.413883  ...          1.754729         -0.051348          1.553547   \n",
       "410689  3.039839  ...          1.855709         -0.208949          1.330966   \n",
       "410690 -1.567403  ...          1.840279          0.185687          1.885126   \n",
       "\n",
       "        ft_concept_3_ref  ft_concept_4_ref  month_ref  day_ref  \\\n",
       "0               2.166929         -2.127061          1        1   \n",
       "1               1.991976         -1.884434          6        1   \n",
       "2               1.605003         -1.850415         12       17   \n",
       "3               1.160670         -1.270961          9        1   \n",
       "4               1.353299         -1.898473          1        1   \n",
       "...                  ...               ...        ...      ...   \n",
       "410686          2.273584         -2.102016          3        5   \n",
       "410687          1.086740         -2.547796          3       27   \n",
       "410688          1.709094         -1.839340          1        1   \n",
       "410689          1.797521         -1.804249          1        1   \n",
       "410690          1.558938         -2.204442          6        1   \n",
       "\n",
       "        primary_author_count_ref  total_cited_by_count_per_site_ref  \\\n",
       "0                              3                        2492.000000   \n",
       "1                              3                        1169.811321   \n",
       "2                              1                         182.000000   \n",
       "3                              1                        1479.000000   \n",
       "4                              1                         645.000000   \n",
       "...                          ...                                ...   \n",
       "410686                         1                         767.000000   \n",
       "410687                         1                        2730.000000   \n",
       "410688                         1                         806.272727   \n",
       "410689                         1                         806.272727   \n",
       "410690                         1                          93.000000   \n",
       "\n",
       "        paper_id_y  \n",
       "0            p3728  \n",
       "1            p3811  \n",
       "2            p3760  \n",
       "3            p1808  \n",
       "4            p2964  \n",
       "...            ...  \n",
       "410686       p2966  \n",
       "410687       p2382  \n",
       "410688       p3209  \n",
       "410689       p0457  \n",
       "410690       p1051  \n",
       "\n",
       "[410691 rows x 217 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ambil hanya kolom numerik dari feature\n",
    "numerical_features = feature.select_dtypes(include='number')\n",
    "numerical_feature_names = numerical_features.columns.tolist()\n",
    "\n",
    "# Tambah kolom 'paper_id' buat join\n",
    "numerical_features['paper_id'] = feature['paper_id']\n",
    "\n",
    "# Merge fitur dari 'paper'\n",
    "train_merged = train.merge(numerical_features, left_on='paper', right_on='paper_id', how='left')\n",
    "train_merged = train_merged.rename(columns={col: f'{col}_paper' for col in numerical_feature_names})\n",
    "\n",
    "# Merge fitur dari 'referenced_paper'\n",
    "train_merged = train_merged.merge(numerical_features, left_on='referenced_paper', right_on='paper_id', how='left')\n",
    "train_merged = train_merged.rename(columns={col: f'{col}_ref' for col in numerical_feature_names})\n",
    "\n",
    "# Drop kolom ID hasil merge yang gak dipakai\n",
    "train_merged\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B.) Publication Date Feature Engineering (Paper and Source)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.149924Z",
     "iopub.status.idle": "2025-04-21T18:51:37.150220Z",
     "shell.execute_reply": "2025-04-21T18:51:37.150082Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.150068Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set index biar lookup cepet\n",
    "pub_date_dict = feature.set_index('paper_id')['publication_date'].to_dict()\n",
    "\n",
    "# Mapping aman\n",
    "train_merged['publish_date_ref'] = train_merged['referenced_paper'].map(pub_date_dict)\n",
    "train_merged['publish_date_paper'] = train_merged['paper'].map(pub_date_dict)\n",
    "\n",
    "# Convert ke datetime\n",
    "train_merged['publish_date_ref'] = pd.to_datetime(train_merged['publish_date_ref'], errors='coerce')\n",
    "train_merged['publish_date_paper'] = pd.to_datetime(train_merged['publish_date_paper'], errors='coerce')\n",
    "\n",
    "# Hitung selisih\n",
    "train_merged['diff_date'] = (train_merged['publish_date_ref'] - train_merged['publish_date_paper']).dt.days\n",
    "train_merged['diff_month'] = train_merged['diff_date'] / 30\n",
    "train_merged['diff_week'] = train_merged['diff_date'] / 7\n",
    "train_merged['diff_exact_year'] = train_merged['diff_date'] / 365\n",
    "train_merged['diff_date'] = train_merged['diff_date'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada bagian ini, kita melakukan rekayasa fitur terkait tanggal publikasi untuk **paper** dan **referenced paper**. Proses ini melibatkan langkah-langkah berikut:\n",
    "\n",
    "1. **Set Index untuk Lookup Cepat**: Mengonversi kolom `paper_id` menjadi indeks untuk memungkinkan pencarian tanggal publikasi yang lebih cepat.\n",
    "   \n",
    "2. **Mapping Tanggal Publikasi**: Menggunakan `map()` untuk menambahkan tanggal publikasi dari `paper_id` ke dalam kolom `publish_date_ref` dan `publish_date_paper`.\n",
    "\n",
    "3. **Konversi ke Format Tanggal**: Mengonversi nilai tanggal publikasi menjadi format datetime menggunakan `pd.to_datetime()`.\n",
    "\n",
    "4. **Menghitung Selisih Tanggal**: Menentukan selisih antara tanggal publikasi referensi dan tanggal publikasi paper dalam satuan hari, bulan, minggu, dan tahun.\n",
    "\n",
    "5. **Penanganan Nilai Kosong**: Mengisi nilai kosong pada `diff_date` dengan nilai 0 dan mengonversinya menjadi integer.\n",
    "\n",
    "Langkah-langkah ini memberikan informasi waktu yang berguna untuk analisis lebih lanjut dan model pelatihan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.151754Z",
     "iopub.status.idle": "2025-04-21T18:51:37.152059Z",
     "shell.execute_reply": "2025-04-21T18:51:37.151917Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.151904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rows_to_drop = train_merged[(train_merged['label'] == 1) & (train_merged['publication_year_paper'] < train_merged['publication_year_ref'])]\n",
    "indices_to_drop = rows_to_drop.index\n",
    "train_merged = train_merged.drop(indices_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagian ini hanyalah asumsi awal kami dimana jika ada paper yang mengsitasi paper lain , maka haruslah tahun nya lebih baru dibanding tahun yang lama "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C.) Vector Feature Engineering (Paper and Reference)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Similarity Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.152759Z",
     "iopub.status.idle": "2025-04-21T18:51:37.153054Z",
     "shell.execute_reply": "2025-04-21T18:51:37.152918Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.152904Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Doc2Vec Metrics: 100%|██████████| 410631/410631 [06:48<00:00, 1005.48it/s]\n",
      "Calculating Title FastText Metrics: 100%|██████████| 410631/410631 [07:11<00:00, 951.55it/s] \n",
      "Calculating Concept FastText Metrics: 100%|██████████| 410631/410631 [07:08<00:00, 958.03it/s] \n"
     ]
    }
   ],
   "source": [
    "def get_doc_vector(pid):\n",
    "    try:\n",
    "        return modeldoc.dv[pid]\n",
    "    except KeyError:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "def get_title_vector(pid):\n",
    "    try:\n",
    "        return modeltitle_ft.wv[pid]\n",
    "    except KeyError:\n",
    "        return np.zeros(modeltitle_ft.vector_size)\n",
    "    \n",
    "def get_concept_vector(pid):\n",
    "    try:\n",
    "        return modelconcept_ft.wv[pid]\n",
    "    except KeyError:\n",
    "        return np.zeros(modelconcept_ft.vector_size)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import euclidean, cityblock\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Doc2Vec calculations\n",
    "doc_cosine_sims = []\n",
    "doc_euclidean_dists = []\n",
    "doc_manhattan_dists = []\n",
    "doc_pearson_corrs = []\n",
    "\n",
    "for i, row in tqdm(train_merged.iterrows(), total=len(train_merged), desc=\"Calculating Doc2Vec Metrics\"):\n",
    "    vec1 = get_doc_vector(row['paper'])\n",
    "    vec2 = get_doc_vector(row['referenced_paper'])\n",
    "    \n",
    "    # Cosine similarity\n",
    "    cosine_sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    doc_cosine_sims.append(cosine_sim)\n",
    "    \n",
    "    # Euclidean distance\n",
    "    euc_dist = euclidean(vec1, vec2)\n",
    "    doc_euclidean_dists.append(euc_dist)\n",
    "    \n",
    "    # Manhattan distance\n",
    "    man_dist = cityblock(vec1, vec2)\n",
    "    doc_manhattan_dists.append(man_dist)\n",
    "    \n",
    "    # Pearson correlation\n",
    "    # Handle case where vectors have zero variance\n",
    "    if np.var(vec1) > 0 and np.var(vec2) > 0:\n",
    "        pearson_corr, _ = pearsonr(vec1, vec2)\n",
    "        doc_pearson_corrs.append(pearson_corr)\n",
    "    else:\n",
    "        doc_pearson_corrs.append(0.0)  # Default value for constant vectors\n",
    "\n",
    "train_merged['doc2vec_cosine_sim'] = doc_cosine_sims\n",
    "train_merged['doc2vec_euclidean_dist'] = doc_euclidean_dists\n",
    "train_merged['doc2vec_manhattan_dist'] = doc_manhattan_dists\n",
    "train_merged['doc2vec_pearson_corr'] = doc_pearson_corrs\n",
    "\n",
    "# Title FastText calculations\n",
    "title_cosine_sims = []\n",
    "title_euclidean_dists = []\n",
    "title_manhattan_dists = []\n",
    "title_pearson_corrs = []\n",
    "\n",
    "for i, row in tqdm(train_merged.iterrows(), total=len(train_merged), desc=\"Calculating Title FastText Metrics\"):\n",
    "    vec1 = get_title_vector(row['paper'])\n",
    "    vec2 = get_title_vector(row['referenced_paper'])\n",
    "    \n",
    "    # Cosine similarity\n",
    "    cosine_sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    title_cosine_sims.append(cosine_sim)\n",
    "    \n",
    "    # Euclidean distance\n",
    "    euc_dist = euclidean(vec1, vec2)\n",
    "    title_euclidean_dists.append(euc_dist)\n",
    "    \n",
    "    # Manhattan distance\n",
    "    man_dist = cityblock(vec1, vec2)\n",
    "    title_manhattan_dists.append(man_dist)\n",
    "    \n",
    "    # Pearson correlation\n",
    "    if np.var(vec1) > 0 and np.var(vec2) > 0:\n",
    "        pearson_corr, _ = pearsonr(vec1, vec2)\n",
    "        title_pearson_corrs.append(pearson_corr)\n",
    "    else:\n",
    "        title_pearson_corrs.append(0.0)\n",
    "\n",
    "train_merged['title_cosine_sim'] = title_cosine_sims\n",
    "train_merged['title_euclidean_dist'] = title_euclidean_dists\n",
    "train_merged['title_manhattan_dist'] = title_manhattan_dists\n",
    "train_merged['title_pearson_corr'] = title_pearson_corrs\n",
    "\n",
    "# Concept FastText calculations\n",
    "concept_cosine_sims = []\n",
    "concept_euclidean_dists = []\n",
    "concept_manhattan_dists = []\n",
    "concept_pearson_corrs = []\n",
    "\n",
    "for i, row in tqdm(train_merged.iterrows(), total=len(train_merged), desc=\"Calculating Concept FastText Metrics\"):\n",
    "    vec1 = get_concept_vector(row['paper'])\n",
    "    vec2 = get_concept_vector(row['referenced_paper'])\n",
    "    \n",
    "    # Cosine similarity\n",
    "    cosine_sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    concept_cosine_sims.append(cosine_sim)\n",
    "    \n",
    "    # Euclidean distance\n",
    "    euc_dist = euclidean(vec1, vec2)\n",
    "    concept_euclidean_dists.append(euc_dist)\n",
    "    \n",
    "    # Manhattan distance\n",
    "    man_dist = cityblock(vec1, vec2)\n",
    "    concept_manhattan_dists.append(man_dist)\n",
    "    \n",
    "    # Pearson correlation\n",
    "    if np.var(vec1) > 0 and np.var(vec2) > 0:\n",
    "        pearson_corr, _ = pearsonr(vec1, vec2)\n",
    "        concept_pearson_corrs.append(pearson_corr)\n",
    "    else:\n",
    "        concept_pearson_corrs.append(0.0)\n",
    "\n",
    "train_merged['concept_cosine_sim'] = concept_cosine_sims\n",
    "train_merged['concept_euclidean_dist'] = concept_euclidean_dists\n",
    "train_merged['concept_manhattan_dist'] = concept_manhattan_dists\n",
    "train_merged['concept_pearson_corr'] = concept_pearson_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SPECTER Metrics: 100%|██████████| 410631/410631 [06:23<00:00, 1070.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import euclidean, cityblock\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Build embedding dictionary\n",
    "specter_embedding_dict = {\n",
    "    row['paper_id']: row[[f'specter_title_{i}' for i in range(768)]].values.astype(np.float32)\n",
    "    for _, row in title_dfz.iterrows()\n",
    "}\n",
    "\n",
    "cosine_sims = []\n",
    "euclidean_dists = []\n",
    "manhattan_dists = []\n",
    "pearson_corrs = []\n",
    "\n",
    "for _, row in tqdm(train_merged.iterrows(), total=len(train_merged), desc=\"SPECTER Metrics\"):\n",
    "    pid1 = row['paper']\n",
    "    pid2 = row['referenced_paper']\n",
    "    \n",
    "    if pid1 in specter_embedding_dict and pid2 in specter_embedding_dict:\n",
    "        vec1 = specter_embedding_dict[pid1]\n",
    "        vec2 = specter_embedding_dict[pid2]\n",
    "\n",
    "        cosine_sims.append(cosine_similarity([vec1], [vec2])[0][0])\n",
    "        euclidean_dists.append(euclidean(vec1, vec2))\n",
    "        manhattan_dists.append(cityblock(vec1, vec2))\n",
    "\n",
    "        try:\n",
    "            pearson_corrs.append(pearsonr(vec1, vec2)[0])\n",
    "        except:\n",
    "            pearson_corrs.append(0.0)\n",
    "    else:\n",
    "        cosine_sims.append(0.0)\n",
    "        euclidean_dists.append(0.0)\n",
    "        manhattan_dists.append(0.0)\n",
    "        pearson_corrs.append(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged['specter_cosine_sim'] = cosine_sims\n",
    "train_merged['specter_euclidean_dist'] = euclidean_dists\n",
    "train_merged['specter_manhattan_dist'] = manhattan_dists\n",
    "train_merged['specter_pearson_corr'] = pearson_corrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SPECTER Metrics: 100%|██████████| 410631/410631 [06:22<00:00, 1072.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import euclidean, cityblock\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Build embedding dictionary\n",
    "specter_embedding_dict = {\n",
    "    row['paper_id']: row[[f'specter_concepts_title_{i}' for i in range(768)]].values.astype(np.float32)\n",
    "    for _, row in concept_dfz.iterrows()\n",
    "}\n",
    "\n",
    "cosine_sims = []\n",
    "euclidean_dists = []\n",
    "manhattan_dists = []\n",
    "pearson_corrs = []\n",
    "\n",
    "for _, row in tqdm(train_merged.iterrows(), total=len(train_merged), desc=\"SPECTER Metrics\"):\n",
    "    pid1 = row['paper']\n",
    "    pid2 = row['referenced_paper']\n",
    "    \n",
    "    if pid1 in specter_embedding_dict and pid2 in specter_embedding_dict:\n",
    "        vec1 = specter_embedding_dict[pid1]\n",
    "        vec2 = specter_embedding_dict[pid2]\n",
    "\n",
    "        cosine_sims.append(cosine_similarity([vec1], [vec2])[0][0])\n",
    "        euclidean_dists.append(euclidean(vec1, vec2))\n",
    "        manhattan_dists.append(cityblock(vec1, vec2))\n",
    "\n",
    "        try:\n",
    "            pearson_corrs.append(pearsonr(vec1, vec2)[0])\n",
    "        except:\n",
    "            pearson_corrs.append(0.0)\n",
    "    else:\n",
    "        cosine_sims.append(0.0)\n",
    "        euclidean_dists.append(0.0)\n",
    "        manhattan_dists.append(0.0)\n",
    "        pearson_corrs.append(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged['specter_cosine_sim_concepts'] = cosine_sims\n",
    "train_merged['specter_euclidean_concepts_dist'] = euclidean_dists\n",
    "train_merged['specter_manhattan_concepts_dist'] = manhattan_dists\n",
    "train_merged['specter_pearson_concepts_corr'] = pearson_corrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tahap ini, kita menggunakan beberapa metrik untuk mengukur kesamaan antara dua dokumen berdasarkan representasi vektor yang dihasilkan oleh model seperti **Doc2Vec** ,**FastText** dan **BERT (AllenAi)**. Berikut adalah penjelasan tentang beberapa metrik yang digunakan:\n",
    "\n",
    "##### **A. Cosine Similarity**\n",
    "Cosine similarity mengukur kesamaan dua vektor dengan menghitung sudut antara mereka dalam ruang vektor. Nilai cosine similarity berkisar antara -1 hingga 1, di mana:\n",
    "- **1** berarti kedua vektor sangat mirip (sejajar),\n",
    "- **0** berarti kedua vektor tidak ada kesamaan arah,\n",
    "- **-1** berarti kedua vektor berlawanan arah.\n",
    "\n",
    "Rumus cosine similarity adalah sebagai berikut:\n",
    "$$\n",
    "\\text{cosine\\_similarity} = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}\n",
    "$$\n",
    "Di mana \\( A \\) dan \\( B \\) adalah dua vektor yang dibandingkan, dan \\( \\|A\\| \\) serta \\( \\|B\\| \\) adalah panjang (norma) dari masing-masing vektor.\n",
    "\n",
    "##### **B. Euclidean Distance**\n",
    "Euclidean distance adalah ukuran jarak lurus antara dua titik dalam ruang vektor. Semakin kecil jarak Euclidean, semakin mirip dua dokumen tersebut. Rumusnya mirip dengan menghitung jarak fisik antara dua titik di ruang 2D atau 3D:\n",
    "$$\n",
    "d = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$\n",
    "Di sini, **x** dan **y** adalah dua vektor dokumen yang dibandingkan, dan **n** adalah jumlah dimensi (fitur) pada vektor. Metrik ini sangat sensitif terhadap skala dan magnitudo vektor.\n",
    "\n",
    "##### **C. Manhattan Distance**\n",
    "Manhattan distance (juga dikenal sebagai L1 distance) mengukur jarak antara dua vektor dengan menghitung jumlah nilai absolut perbedaan antara setiap dimensi vektor:\n",
    "$$\n",
    "d = \\sum_{i=1}^{n} |x_i - y_i|\n",
    "$$\n",
    "Metrik ini mirip dengan Euclidean, namun lebih fokus pada perbedaan total sepanjang setiap dimensi tanpa memperhitungkan arah, yang dapat lebih berguna dalam konteks data dengan banyak variabel yang tidak sebanding.\n",
    "\n",
    "##### **D. Pearson Correlation**\n",
    "Pearson correlation mengukur hubungan linier antara dua vektor. Nilai Pearson correlation berkisar antara -1 hingga 1, di mana:\n",
    "- **1** menunjukkan korelasi positif sempurna (kedua vektor bergerak bersama ke arah yang sama),\n",
    "- **-1** menunjukkan korelasi negatif sempurna (kedua vektor bergerak berlawanan),\n",
    "- **0** menunjukkan tidak ada korelasi linier.\n",
    "\n",
    "Rumus Pearson correlation adalah sebagai berikut:\n",
    "$$\n",
    "r = \\frac{\\sum{(x_i - \\bar{x})(y_i - \\bar{y})}}{\\sqrt{\\sum{(x_i - \\bar{x})^2} \\sum{(y_i - \\bar{y})^2}}}\n",
    "$$\n",
    "Di mana $ x_i $ dan $ y_i $ adalah nilai-nilai elemen dalam dua vektor, dan $ \\bar{x} $ dan $ \\bar{y} $ adalah rata-rata dari masing-masing vektor.\n",
    "\n",
    "---\n",
    "\n",
    "Dengan menggunakan berbagai metrik ini, kita dapat memperoleh gambaran lebih lengkap tentang bagaimana dua dokumen saling terkait, baik dari segi kesamaan kontekstual, jarak fisik dalam ruang vektor, maupun hubungan linier antar elemen-elemen dalam dokumen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Scalar Vector Calculation (Paper and Reference)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating doc2vec Scalar Features: 100%|██████████| 410631/410631 [01:04<00:00, 6380.04it/s]\n",
      "Calculating title Scalar Features: 100%|██████████| 410631/410631 [01:23<00:00, 4903.45it/s]\n",
      "Calculating concept Scalar Features: 100%|██████████| 410631/410631 [01:26<00:00, 4750.60it/s]\n"
     ]
    }
   ],
   "source": [
    "def calculate_scalar_vector_features(df, col1, col2, get_vector_func, prefix):\n",
    "    mean_combineds = []\n",
    "    std_diffs = []\n",
    "    sq_diff_sums = []\n",
    "    abs_diff_sums = []\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=f\"Calculating {prefix} Scalar Features\"):\n",
    "        vec1 = get_vector_func(row[col1])\n",
    "        vec2 = get_vector_func(row[col2])\n",
    "\n",
    "        mean_combined = np.mean(np.concatenate([vec1, vec2]))\n",
    "        std_diff = np.std(vec1 - vec2)\n",
    "        sq_diff_sum = np.sum((vec1 - vec2) ** 2)\n",
    "        abs_diff_sum = np.sum(np.abs(vec1 - vec2))\n",
    "\n",
    "        mean_combineds.append(mean_combined)\n",
    "        std_diffs.append(std_diff)\n",
    "        sq_diff_sums.append(sq_diff_sum)\n",
    "        abs_diff_sums.append(abs_diff_sum)\n",
    "\n",
    "    df[f'{prefix}_mean_combined'] = mean_combineds\n",
    "    df[f'{prefix}_std_diff'] = std_diffs\n",
    "    df[f'{prefix}_sq_diff_sum'] = sq_diff_sums\n",
    "    df[f'{prefix}_abs_diff_sum'] = abs_diff_sums\n",
    "\n",
    "calculate_scalar_vector_features(\n",
    "    train_merged, 'paper', 'referenced_paper', get_doc_vector, prefix='doc2vec'\n",
    ")\n",
    "\n",
    "calculate_scalar_vector_features(\n",
    "    train_merged, 'paper', 'referenced_paper', get_title_vector, prefix='title'\n",
    ")\n",
    "\n",
    "calculate_scalar_vector_features(\n",
    "    train_merged, 'paper', 'referenced_paper', get_concept_vector, prefix='concept'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selain menghitung kemiripan dan jarak antar vektor, kami juga menambahkan fitur **berbasis skalar** yang dihitung dari perbedaan antara dua vektor representasi (vektor dari dokumen yang mengutip dan yang dikutip).\n",
    "\n",
    "Fitur-fitur yang dihitung adalah:\n",
    "\n",
    "- **Rata-rata Gabungan Vektor** $$ \\text{mean}([v_1, v_2]) $$\n",
    "  Mengukur nilai rata-rata dari dua vektor yang digabung. Bisa mencerminkan \"pusat\" dari kedua representasi.\n",
    "\n",
    "- **Standar Deviasi dari Selisih Vektor** $$ \\text{std}(v_1 - v_2) $$\n",
    "  Mengukur seberapa besar variasi dari perbedaan antara dua vektor.\n",
    "\n",
    "- **Jumlah Kuadrat Selisih** $$ \\sum (v_1 - v_2)^2 $$\n",
    "  Mirip dengan Euclidean Distance, tapi tanpa akar kuadrat. Memberi indikasi seberapa besar \"energi\" perbedaan antar elemen vektor.\n",
    "\n",
    "- **Jumlah Nilai Absolut Selisih** $$ \\sum |v_1 - v_2| $$ \n",
    "  Seperti Manhattan Distance, menggambarkan total jarak langsung di tiap dimensi antara dua vektor.\n",
    "\n",
    "Fitur-fitur ini kami hitung untuk:\n",
    "- **Representasi Doc2Vec**\n",
    "- **Representasi FastText Judul**\n",
    "- **Representasi FastText Konsep**\n",
    "\n",
    "> Namun **tidak** kami hitung untuk representasi vektor dari **AllenAI SPECTER BERT**, karena keterbatasan waktu saat proses rekayasa fitur (_feature engineering_).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Angular Similarity Feature Extraction (Paper and Reference)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating doc2vec Divergence Features: 100%|██████████| 410631/410631 [03:50<00:00, 1781.28it/s]\n",
      "Calculating title Divergence Features: 100%|██████████| 410631/410631 [04:15<00:00, 1609.24it/s]\n",
      "Calculating concept Divergence Features: 100%|██████████| 410631/410631 [04:20<00:00, 1575.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def calculate_vector_divergence_features(df, col1, col2, get_vector_func, prefix):\n",
    "    angles = []\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=f\"Calculating {prefix} Divergence Features\"):\n",
    "        vec1 = get_vector_func(row[col1])\n",
    "        vec2 = get_vector_func(row[col2])\n",
    "        \n",
    "        # Angle (arccos of cosine similarity)\n",
    "        cos_sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "        angle = np.arccos(np.clip(cos_sim, -1.0, 1.0))  # Clip to avoid NaNs\n",
    "        angles.append(angle)\n",
    "\n",
    "    df[f'{prefix}_angle'] = angles\n",
    "\n",
    "calculate_vector_divergence_features(\n",
    "    train_merged, 'paper', 'referenced_paper', get_doc_vector, prefix='doc2vec'\n",
    ")\n",
    "\n",
    "calculate_vector_divergence_features(\n",
    "    train_merged, 'paper', 'referenced_paper', get_title_vector, prefix='title'\n",
    ")\n",
    "calculate_vector_divergence_features(\n",
    "    train_merged, 'paper', 'referenced_paper', get_concept_vector, prefix='concept'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk menambahkan informasi tambahan mengenai perbedaan arah dari dua vektor representasi, kami menghitung **sudut antar vektor** berdasarkan **cosine similarity**.\n",
    "\n",
    "**Fitur yang dihitung**:\n",
    "\n",
    "- **Sudut antara dua vektor**  \n",
    "  Dihitung menggunakan rumus:\n",
    "\n",
    "  $$\n",
    "  \\theta = \\cos^{-1}(\\text{cosine similarity}(v_1, v_2))\n",
    "  $$\n",
    "\n",
    "  Nilai ini mencerminkan **perbedaan arah** antara dua vektor. Jika dua vektor mengarah ke arah yang sama, maka sudutnya kecil (mendekati 0). Sebaliknya, jika berlawanan arah, maka sudutnya besar (mendekati π).\n",
    "\n",
    "Kenapa penting?\n",
    "Sudut ini bisa jadi indikator apakah dua dokumen memiliki **arah semantik yang sama atau tidak**, meskipun secara magnitudo mungkin berbeda. Ini berguna saat vektor sudah dinormalisasi atau ketika kita ingin melihat \"sejauh mana dua dokumen membicarakan hal yang sejenis\".\n",
    "\n",
    "**Fitur ini kami hitung untuk**:\n",
    "\n",
    "- **Representasi Doc2Vec**\n",
    "- **Representasi FastText Judul**\n",
    "- **Representasi FastText Konsep**\n",
    "\n",
    "> Sama seperti sebelumnya, fitur ini **tidak dihitung** untuk representasi **AllenAI SPECTER BERT** karena keterbatasan waktu pada tahap eksperimen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Directional Relevance (Paper and Reference)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating doc2vec NN-like Features: 100%|██████████| 410631/410631 [00:30<00:00, 13407.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "def calculate_advanced_vector_features(df, col1, col2, get_vector_func, prefix):\n",
    "    projections = []\n",
    "  \n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=f\"Calculating {prefix} NN-like Features\"):\n",
    "        vec1 = get_vector_func(row[col1])\n",
    "        vec2 = get_vector_func(row[col2])\n",
    "        \n",
    "        projection = np.dot(vec1, vec2) / (np.linalg.norm(vec2) + 1e-8)\n",
    "        projections.append(projection)\n",
    "\n",
    "    df[f'{prefix}_projection'] = projections\n",
    "\n",
    "calculate_advanced_vector_features(\n",
    "    train_merged, 'paper', 'referenced_paper', get_doc_vector, prefix='doc2vec'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitur ini digunakan untuk mengukur **seberapa besar vektor pertama memproyeksikan dirinya ke arah vektor kedua**. Dalam konteks teks atau dokumen, ini bisa menggambarkan seberapa besar satu dokumen \"mengandung\" arah semantik dari dokumen lainnya.\n",
    "\n",
    "**Rumus Proyeksi**:\n",
    "\n",
    "$$\n",
    "\\text{Proyeksi} = \\frac{\\vec{a} \\cdot \\vec{b}}{\\|\\vec{b}\\|}\n",
    "$$\n",
    "\n",
    "- $ \\vec{a} \\cdot \\vec{b} $ adalah dot product antara dua vektor.\n",
    "- $ \\|\\vec{b}\\| $ adalah panjang (norm) dari vektor kedua.\n",
    "\n",
    "**Interpretasi Nilai**:\n",
    "- Nilai **besar dan positif** → vektor $ \\vec{a} $ searah dengan $ \\vec{b} $.\n",
    "- Nilai **kecil** → vektor $ \\vec{a} $ kurang sejajar dengan $ \\vec{b} $.\n",
    "- Bisa berguna untuk melihat **sejauh mana satu dokumen mengikuti arah semantik** dari dokumen referensinya.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model and Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.154253Z",
     "iopub.status.idle": "2025-04-21T18:51:37.154551Z",
     "shell.execute_reply": "2025-04-21T18:51:37.154414Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.154401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = train_merged.select_dtypes(include='number')\n",
    "X = X.drop(columns=['label'])\n",
    "y = train_merged['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.155804Z",
     "iopub.status.idle": "2025-04-21T18:51:37.156099Z",
     "shell.execute_reply": "2025-04-21T18:51:37.155962Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.155949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X['now_year_paper'] = 2025 - X['publication_year_paper']\n",
    "X['now_year_ref'] = 2025 - X['publication_year_ref']\n",
    "\n",
    "X['diff_age'] = X['now_year_paper'] - X['now_year_ref']\n",
    "X['ratio_age'] = X['now_year_ref'] / (X['now_year_paper'] + 1e-5)  # Hindari div by zero\n",
    "\n",
    "\n",
    "X['citation_diff'] = X['cited_by_count_paper'] - X['cited_by_count_ref']\n",
    "X['citation_ratio'] = X['cited_by_count_ref'] / (X['cited_by_count_paper'] + 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sedikit menggeneralisasi ide sebelumnya dan menambahkan elemen terkait tahun atau tanggal publikasi. Mengingat bahwa fitur tahun atau tanggal sangat berpengaruh dalam pemilihan referensi di dunia nyata, hal ini penting untuk diperhatikan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Optuna (Hyperparameter Tuning) → Optional**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T18:51:37.157095Z",
     "iopub.status.idle": "2025-04-21T18:51:37.157297Z",
     "shell.execute_reply": "2025-04-21T18:51:37.157210Z",
     "shell.execute_reply.started": "2025-04-21T18:51:37.157202Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.metrics import matthews_corrcoef\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# import numpy as np\n",
    "# import optuna\n",
    "\n",
    "# def objective(trial):\n",
    "#     # Hyperparameter space\n",
    "#     # iterations = trial.suggest_int('iterations', 2000, 3000, step=25)\n",
    "#     # learning_rate = trial.suggest_float('learning_rate', 0.05, 0.3, log=True)\n",
    "#     l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 10)\n",
    "    \n",
    "#     # Feature-selected matrix (optional)\n",
    "#     X_selected = X\n",
    "\n",
    "#     # Train-test split\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X_selected, y, test_size=0.17, stratify=y, random_state=42)\n",
    "\n",
    "#     # Oversampling\n",
    "#     ros = RandomOverSampler(random_state=42)\n",
    "#     X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "#     # Train CatBoost\n",
    "#     model = CatBoostClassifier(\n",
    "#         iterations=2850,\n",
    "#         learning_rate=0.12860233569187382,\n",
    "#         l2_leaf_reg=l2_leaf_reg,\n",
    "#         verbose=0,\n",
    "#         random_state=42,\n",
    "#         grow_policy='Lossguide',\n",
    "#         task_type='GPU'\n",
    "#     )\n",
    "    \n",
    "#     model.fit(X_resampled, y_resampled)\n",
    "\n",
    "#     # Predict probabilities on validation\n",
    "#     y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "#     # Search best threshold by MCC\n",
    "#     thresholds = np.linspace(0.01, 0.99, 100)\n",
    "#     best_mcc = -1\n",
    "#     best_threshold = 0.5\n",
    "\n",
    "#     for threshold in thresholds:\n",
    "#         y_pred_thresholded = (y_pred_proba >= threshold).astype(int)\n",
    "#         mcc = matthews_corrcoef(y_val, y_pred_thresholded)\n",
    "#         if mcc > best_mcc:\n",
    "#             best_mcc = mcc\n",
    "#             best_threshold = threshold\n",
    "\n",
    "#     # Store results\n",
    "#     trial.set_user_attr(\"best_threshold\", best_threshold)\n",
    "\n",
    "#     return best_mcc\n",
    "\n",
    "# # Run Optuna\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=20)\n",
    "\n",
    "# # Print Best Results\n",
    "# print(\"Number of finished trials:\", len(study.trials))\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(\"  Value (Best MCC):\", trial.value)\n",
    "# print(\"  Params:\", trial.params)\n",
    "# print(\"  Best Threshold:\", trial.user_attrs[\"best_threshold\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CatBoost Model → Best Model After Evaluating With Another Model (LightGBM , NN-Based, XGBoost, Random Forest)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5328133\ttotal: 21.6ms\tremaining: 1m 1s\n",
      "50:\tlearn: 0.1008832\ttotal: 963ms\tremaining: 52.8s\n",
      "100:\tlearn: 0.0650173\ttotal: 1.92s\tremaining: 52.3s\n",
      "150:\tlearn: 0.0460914\ttotal: 2.86s\tremaining: 51.2s\n",
      "200:\tlearn: 0.0339644\ttotal: 3.76s\tremaining: 49.5s\n",
      "250:\tlearn: 0.0256395\ttotal: 4.63s\tremaining: 48s\n",
      "300:\tlearn: 0.0196101\ttotal: 5.51s\tremaining: 46.7s\n",
      "350:\tlearn: 0.0152281\ttotal: 6.4s\tremaining: 45.5s\n",
      "400:\tlearn: 0.0120010\ttotal: 7.3s\tremaining: 44.6s\n",
      "450:\tlearn: 0.0094215\ttotal: 8.19s\tremaining: 43.5s\n",
      "500:\tlearn: 0.0074700\ttotal: 9.06s\tremaining: 42.5s\n",
      "550:\tlearn: 0.0059632\ttotal: 9.96s\tremaining: 41.6s\n",
      "600:\tlearn: 0.0047781\ttotal: 10.9s\tremaining: 40.6s\n",
      "650:\tlearn: 0.0038121\ttotal: 11.8s\tremaining: 39.7s\n",
      "700:\tlearn: 0.0030667\ttotal: 12.7s\tremaining: 38.9s\n",
      "750:\tlearn: 0.0024940\ttotal: 13.6s\tremaining: 38.1s\n",
      "800:\tlearn: 0.0020225\ttotal: 14.5s\tremaining: 37.2s\n",
      "850:\tlearn: 0.0016508\ttotal: 15.4s\tremaining: 36.3s\n",
      "900:\tlearn: 0.0013611\ttotal: 16.4s\tremaining: 35.4s\n",
      "950:\tlearn: 0.0011237\ttotal: 17.3s\tremaining: 34.5s\n",
      "1000:\tlearn: 0.0009309\ttotal: 18.2s\tremaining: 33.6s\n",
      "1050:\tlearn: 0.0007780\ttotal: 19.1s\tremaining: 32.8s\n",
      "1100:\tlearn: 0.0006501\ttotal: 20.1s\tremaining: 31.9s\n",
      "1150:\tlearn: 0.0005460\ttotal: 21s\tremaining: 31s\n",
      "1200:\tlearn: 0.0004587\ttotal: 22s\tremaining: 30.2s\n",
      "1250:\tlearn: 0.0003869\ttotal: 23s\tremaining: 29.3s\n",
      "1300:\tlearn: 0.0003269\ttotal: 24s\tremaining: 28.5s\n",
      "1350:\tlearn: 0.0002768\ttotal: 24.9s\tremaining: 27.7s\n",
      "1400:\tlearn: 0.0002361\ttotal: 25.9s\tremaining: 26.8s\n",
      "1450:\tlearn: 0.0002013\ttotal: 26.9s\tremaining: 25.9s\n",
      "1500:\tlearn: 0.0001720\ttotal: 27.9s\tremaining: 25s\n",
      "1550:\tlearn: 0.0001475\ttotal: 28.8s\tremaining: 24.2s\n",
      "1600:\tlearn: 0.0001271\ttotal: 29.8s\tremaining: 23.3s\n",
      "1650:\tlearn: 0.0001100\ttotal: 30.8s\tremaining: 22.4s\n",
      "1700:\tlearn: 0.0000953\ttotal: 31.8s\tremaining: 21.5s\n",
      "1750:\tlearn: 0.0000827\ttotal: 32.8s\tremaining: 20.6s\n",
      "1800:\tlearn: 0.0000717\ttotal: 33.8s\tremaining: 19.7s\n",
      "1850:\tlearn: 0.0000624\ttotal: 34.9s\tremaining: 18.8s\n",
      "1900:\tlearn: 0.0000546\ttotal: 35.9s\tremaining: 17.9s\n",
      "1950:\tlearn: 0.0000479\ttotal: 36.9s\tremaining: 17s\n",
      "2000:\tlearn: 0.0000423\ttotal: 37.9s\tremaining: 16.1s\n",
      "2050:\tlearn: 0.0000374\ttotal: 38.9s\tremaining: 15.1s\n",
      "2100:\tlearn: 0.0000333\ttotal: 39.8s\tremaining: 14.2s\n",
      "2150:\tlearn: 0.0000298\ttotal: 40.8s\tremaining: 13.3s\n",
      "2200:\tlearn: 0.0000267\ttotal: 41.8s\tremaining: 12.3s\n",
      "2250:\tlearn: 0.0000240\ttotal: 42.8s\tremaining: 11.4s\n",
      "2300:\tlearn: 0.0000217\ttotal: 43.8s\tremaining: 10.5s\n",
      "2350:\tlearn: 0.0000196\ttotal: 44.8s\tremaining: 9.51s\n",
      "2400:\tlearn: 0.0000179\ttotal: 45.8s\tremaining: 8.56s\n",
      "2450:\tlearn: 0.0000164\ttotal: 46.7s\tremaining: 7.61s\n",
      "2500:\tlearn: 0.0000150\ttotal: 47.7s\tremaining: 6.66s\n",
      "2550:\tlearn: 0.0000139\ttotal: 48.7s\tremaining: 5.71s\n",
      "2600:\tlearn: 0.0000128\ttotal: 49.7s\tremaining: 4.75s\n",
      "2650:\tlearn: 0.0000119\ttotal: 50.6s\tremaining: 3.8s\n",
      "2700:\tlearn: 0.0000111\ttotal: 51.6s\tremaining: 2.85s\n",
      "2750:\tlearn: 0.0000104\ttotal: 52.6s\tremaining: 1.89s\n",
      "2800:\tlearn: 0.0000098\ttotal: 53.6s\tremaining: 938ms\n",
      "2849:\tlearn: 0.0000093\ttotal: 54.6s\tremaining: 0us\n",
      "Best Threshold for MCC: 0.1189\n",
      "Best Matthews Correlation Coefficient (MCC) on Validation Set: 0.5842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, ADASYN\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.17, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, y_train = RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
    "\n",
    "model2 = CatBoostClassifier(\n",
    "    iterations=2850,\n",
    "    learning_rate=0.12860233569187382,\n",
    "    grow_policy='Lossguide',\n",
    "    task_type='GPU',\n",
    "    verbose=50,  \n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = model2.predict_proba(X_val)[:, 1]\n",
    "thresholds = np.linspace(0.01, 0.99, 100)  \n",
    "\n",
    "best_mcc = -1\n",
    "best_threshold = 0.5\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresholded = (y_pred_proba >= threshold).astype(int)\n",
    "    mcc = matthews_corrcoef(y_val, y_pred_thresholded)\n",
    "    if mcc > best_mcc:\n",
    "        best_mcc = mcc\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f'Best Threshold for MCC: {best_threshold:.4f}')\n",
    "print(f'Best Matthews Correlation Coefficient (MCC) on Validation Set: {best_mcc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stratified KFold Cross Validation → Imbalanced Case Validation (Optional)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.metrics import matthews_corrcoef\n",
    "# import numpy as np\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# X = pd.DataFrame(X)\n",
    "# y = pd.Series(y)\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# best_mccs = []\n",
    "# best_thresholds = []\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "#     print(f\"\\n--- Fold {fold + 1} ---\")\n",
    "\n",
    "#     X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#     y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "#     # Resampling\n",
    "#     X_train, y_train = RandomOverSampler(random_state=42, sampling_strategy=1).fit_resample(X_train, y_train)\n",
    "\n",
    "#     # Model\n",
    "#     model = CatBoostClassifier(\n",
    "#     iterations=2850,\n",
    "#     learning_rate=0.12860233569187382,\n",
    "#     grow_policy='Lossguide',\n",
    "#     task_type='GPU',\n",
    "#     verbose=1000,  \n",
    "#     random_state=42,\n",
    "#     )\n",
    "\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     # Predict probs\n",
    "#     y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "#     # Threshold tuning for MCC\n",
    "#     thresholds = np.linspace(0.01, 0.99, 100)\n",
    "#     best_mcc = -1\n",
    "#     best_threshold = 0.5\n",
    "\n",
    "#     for threshold in thresholds:\n",
    "#         y_pred_thresholded = (y_pred_proba >= threshold).astype(int)\n",
    "#         mcc = matthews_corrcoef(y_val, y_pred_thresholded)\n",
    "#         if mcc > best_mcc:\n",
    "#             best_mcc = mcc\n",
    "#             best_threshold = threshold\n",
    "\n",
    "#     print(f'Best Threshold: {best_threshold:.4f}')\n",
    "#     print(f'Best MCC: {best_mcc:.4f}')\n",
    "    \n",
    "#     best_mccs.append(best_mcc)\n",
    "#     best_thresholds.append(best_threshold)\n",
    "\n",
    "# print(f\"\\nAverage MCC across folds: {np.mean(best_mccs):.4f}\")\n",
    "# print(f\"Average Best Threshold: {np.mean(best_thresholds):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CatBoost Model Evaluate → Evaluate Best Feature,Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69045    44]\n",
      " [  527   192]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     69089\n",
      "           1       0.81      0.27      0.40       719\n",
      "\n",
      "    accuracy                           0.99     69808\n",
      "   macro avg       0.90      0.63      0.70     69808\n",
      "weighted avg       0.99      0.99      0.99     69808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_val, y_pred_thresholded))\n",
    "print(classification_report(y_val, y_pred_thresholded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Feature Importances (CatBoost):\n",
      "                             Feature  Importance\n",
      "248                    doc2vec_angle    7.974470\n",
      "254                         diff_age    7.878691\n",
      "219             doc2vec_pearson_corr    5.151271\n",
      "216               doc2vec_cosine_sim    4.815026\n",
      "212                        diff_date    4.624389\n",
      "251               doc2vec_projection    3.887883\n",
      "228               specter_cosine_sim    2.176472\n",
      "255                        ratio_age    1.934756\n",
      "107               cited_by_count_ref    1.767992\n",
      "234  specter_manhattan_concepts_dist    0.670408\n",
      "213                       diff_month    0.669177\n",
      "232      specter_cosine_sim_concepts    0.612983\n",
      "231             specter_pearson_corr    0.610638\n",
      "229           specter_euclidean_dist    0.605133\n",
      "131                           23_ref    0.574038\n",
      "257                   citation_ratio    0.478423\n",
      "230           specter_manhattan_dist    0.442790\n",
      "18                          16_paper    0.425593\n",
      "54                          52_paper    0.418723\n",
      "186                           78_ref    0.417918\n",
      "244            concept_mean_combined    0.393199\n",
      "76                          74_paper    0.385018\n",
      "128                           20_ref    0.380267\n",
      "140                           32_ref    0.374457\n",
      "168                           60_ref    0.371266\n",
      "87                          85_paper    0.370514\n",
      "47                          45_paper    0.364004\n",
      "122                           14_ref    0.356260\n",
      "72                          70_paper    0.355618\n",
      "65                          63_paper    0.355364\n",
      "10                           8_paper    0.355334\n",
      "175                           67_ref    0.354771\n",
      "93                  ft_title_1_paper    0.353330\n",
      "80                          78_paper    0.347242\n",
      "101               ft_concept_4_paper    0.346712\n",
      "256                    citation_diff    0.345100\n",
      "172                           64_ref    0.342188\n",
      "156                           48_ref    0.336454\n",
      "71                          69_paper    0.331577\n",
      "7                            5_paper    0.322130\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importances = model2.get_feature_importance()\n",
    "feature_names = X_train.columns  #\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Feature Importances (CatBoost):\")\n",
    "print(importance_df.head(40))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'][:20], importance_df['Importance'][:20])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 10 Feature Importances (CatBoost)')\n",
    "plt.gca().invert_yaxis() \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper</th>\n",
       "      <th>referenced_paper</th>\n",
       "      <th>publication_year_paper</th>\n",
       "      <th>cited_by_count_paper</th>\n",
       "      <th>0_paper</th>\n",
       "      <th>1_paper</th>\n",
       "      <th>2_paper</th>\n",
       "      <th>3_paper</th>\n",
       "      <th>4_paper</th>\n",
       "      <th>5_paper</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_concept_0_ref</th>\n",
       "      <th>ft_concept_1_ref</th>\n",
       "      <th>ft_concept_2_ref</th>\n",
       "      <th>ft_concept_3_ref</th>\n",
       "      <th>ft_concept_4_ref</th>\n",
       "      <th>month_ref</th>\n",
       "      <th>day_ref</th>\n",
       "      <th>primary_author_count_ref</th>\n",
       "      <th>total_cited_by_count_per_site_ref</th>\n",
       "      <th>paper_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0913</td>\n",
       "      <td>p3488</td>\n",
       "      <td>2010</td>\n",
       "      <td>401</td>\n",
       "      <td>-3.316654</td>\n",
       "      <td>-3.898887</td>\n",
       "      <td>-7.122129</td>\n",
       "      <td>8.658471</td>\n",
       "      <td>0.731293</td>\n",
       "      <td>2.668038</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162307</td>\n",
       "      <td>0.272245</td>\n",
       "      <td>1.515264</td>\n",
       "      <td>0.909239</td>\n",
       "      <td>-1.496723</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>933.0</td>\n",
       "      <td>p3488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p2971</td>\n",
       "      <td>p4337</td>\n",
       "      <td>2020</td>\n",
       "      <td>74</td>\n",
       "      <td>-9.606321</td>\n",
       "      <td>-3.714645</td>\n",
       "      <td>-4.974587</td>\n",
       "      <td>-0.396276</td>\n",
       "      <td>-2.339198</td>\n",
       "      <td>6.489149</td>\n",
       "      <td>...</td>\n",
       "      <td>1.529858</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>1.347746</td>\n",
       "      <td>1.384347</td>\n",
       "      <td>-1.729908</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12629.0</td>\n",
       "      <td>p4337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p2237</td>\n",
       "      <td>p1610</td>\n",
       "      <td>2014</td>\n",
       "      <td>349</td>\n",
       "      <td>4.742624</td>\n",
       "      <td>-0.963916</td>\n",
       "      <td>5.322425</td>\n",
       "      <td>1.357907</td>\n",
       "      <td>5.437292</td>\n",
       "      <td>4.114721</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142683</td>\n",
       "      <td>0.494231</td>\n",
       "      <td>2.076965</td>\n",
       "      <td>0.894240</td>\n",
       "      <td>-1.781902</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>3729.0</td>\n",
       "      <td>p1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p2876</td>\n",
       "      <td>p3212</td>\n",
       "      <td>2020</td>\n",
       "      <td>21</td>\n",
       "      <td>0.051383</td>\n",
       "      <td>-1.425694</td>\n",
       "      <td>-2.715291</td>\n",
       "      <td>3.875911</td>\n",
       "      <td>-3.424484</td>\n",
       "      <td>4.246262</td>\n",
       "      <td>...</td>\n",
       "      <td>1.268431</td>\n",
       "      <td>0.539495</td>\n",
       "      <td>2.071610</td>\n",
       "      <td>0.944968</td>\n",
       "      <td>-1.857831</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>274.0</td>\n",
       "      <td>p3212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p2939</td>\n",
       "      <td>p1901</td>\n",
       "      <td>2016</td>\n",
       "      <td>592</td>\n",
       "      <td>1.997982</td>\n",
       "      <td>-3.701062</td>\n",
       "      <td>5.880289</td>\n",
       "      <td>2.135527</td>\n",
       "      <td>-1.644157</td>\n",
       "      <td>9.145401</td>\n",
       "      <td>...</td>\n",
       "      <td>1.778186</td>\n",
       "      <td>0.027219</td>\n",
       "      <td>1.682292</td>\n",
       "      <td>1.705304</td>\n",
       "      <td>-1.974369</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>51.0</td>\n",
       "      <td>p1901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336016</th>\n",
       "      <td>p0778</td>\n",
       "      <td>p2030</td>\n",
       "      <td>2006</td>\n",
       "      <td>348</td>\n",
       "      <td>4.171943</td>\n",
       "      <td>-4.560515</td>\n",
       "      <td>-0.608951</td>\n",
       "      <td>-1.819381</td>\n",
       "      <td>-4.340608</td>\n",
       "      <td>4.959444</td>\n",
       "      <td>...</td>\n",
       "      <td>1.344092</td>\n",
       "      <td>0.450436</td>\n",
       "      <td>2.046958</td>\n",
       "      <td>0.945849</td>\n",
       "      <td>-1.890467</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>176.0</td>\n",
       "      <td>p2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336017</th>\n",
       "      <td>p3656</td>\n",
       "      <td>p2661</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.832230</td>\n",
       "      <td>-3.556752</td>\n",
       "      <td>-1.684169</td>\n",
       "      <td>-0.130252</td>\n",
       "      <td>-1.244321</td>\n",
       "      <td>3.060801</td>\n",
       "      <td>...</td>\n",
       "      <td>1.722812</td>\n",
       "      <td>0.267425</td>\n",
       "      <td>2.047756</td>\n",
       "      <td>1.266611</td>\n",
       "      <td>-2.208189</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>223.0</td>\n",
       "      <td>p2661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336018</th>\n",
       "      <td>p3088</td>\n",
       "      <td>p2517</td>\n",
       "      <td>2020</td>\n",
       "      <td>962</td>\n",
       "      <td>0.538783</td>\n",
       "      <td>-7.101543</td>\n",
       "      <td>3.646557</td>\n",
       "      <td>2.295797</td>\n",
       "      <td>1.732916</td>\n",
       "      <td>4.470127</td>\n",
       "      <td>...</td>\n",
       "      <td>2.001780</td>\n",
       "      <td>-0.073776</td>\n",
       "      <td>1.723726</td>\n",
       "      <td>1.916270</td>\n",
       "      <td>-2.156454</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>p2517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336019</th>\n",
       "      <td>p1789</td>\n",
       "      <td>p2958</td>\n",
       "      <td>2020</td>\n",
       "      <td>87</td>\n",
       "      <td>3.129496</td>\n",
       "      <td>2.335075</td>\n",
       "      <td>-3.887223</td>\n",
       "      <td>-0.960167</td>\n",
       "      <td>-0.905979</td>\n",
       "      <td>-4.509037</td>\n",
       "      <td>...</td>\n",
       "      <td>1.735124</td>\n",
       "      <td>-0.030038</td>\n",
       "      <td>1.726534</td>\n",
       "      <td>1.620107</td>\n",
       "      <td>-1.920763</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1379.0</td>\n",
       "      <td>p2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336020</th>\n",
       "      <td>p2983</td>\n",
       "      <td>p2109</td>\n",
       "      <td>2021</td>\n",
       "      <td>1292</td>\n",
       "      <td>2.332113</td>\n",
       "      <td>3.655634</td>\n",
       "      <td>5.076507</td>\n",
       "      <td>1.587439</td>\n",
       "      <td>2.573779</td>\n",
       "      <td>0.554789</td>\n",
       "      <td>...</td>\n",
       "      <td>1.509166</td>\n",
       "      <td>0.143271</td>\n",
       "      <td>1.668723</td>\n",
       "      <td>1.422292</td>\n",
       "      <td>-1.786957</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>p2109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336021 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        paper referenced_paper  publication_year_paper  cited_by_count_paper  \\\n",
       "0       p0913            p3488                    2010                   401   \n",
       "1       p2971            p4337                    2020                    74   \n",
       "2       p2237            p1610                    2014                   349   \n",
       "3       p2876            p3212                    2020                    21   \n",
       "4       p2939            p1901                    2016                   592   \n",
       "...       ...              ...                     ...                   ...   \n",
       "336016  p0778            p2030                    2006                   348   \n",
       "336017  p3656            p2661                    2021                     5   \n",
       "336018  p3088            p2517                    2020                   962   \n",
       "336019  p1789            p2958                    2020                    87   \n",
       "336020  p2983            p2109                    2021                  1292   \n",
       "\n",
       "         0_paper   1_paper   2_paper   3_paper   4_paper   5_paper  ...  \\\n",
       "0      -3.316654 -3.898887 -7.122129  8.658471  0.731293  2.668038  ...   \n",
       "1      -9.606321 -3.714645 -4.974587 -0.396276 -2.339198  6.489149  ...   \n",
       "2       4.742624 -0.963916  5.322425  1.357907  5.437292  4.114721  ...   \n",
       "3       0.051383 -1.425694 -2.715291  3.875911 -3.424484  4.246262  ...   \n",
       "4       1.997982 -3.701062  5.880289  2.135527 -1.644157  9.145401  ...   \n",
       "...          ...       ...       ...       ...       ...       ...  ...   \n",
       "336016  4.171943 -4.560515 -0.608951 -1.819381 -4.340608  4.959444  ...   \n",
       "336017 -1.832230 -3.556752 -1.684169 -0.130252 -1.244321  3.060801  ...   \n",
       "336018  0.538783 -7.101543  3.646557  2.295797  1.732916  4.470127  ...   \n",
       "336019  3.129496  2.335075 -3.887223 -0.960167 -0.905979 -4.509037  ...   \n",
       "336020  2.332113  3.655634  5.076507  1.587439  2.573779  0.554789  ...   \n",
       "\n",
       "        ft_concept_0_ref  ft_concept_1_ref  ft_concept_2_ref  \\\n",
       "0               1.162307          0.272245          1.515264   \n",
       "1               1.529858          0.013594          1.347746   \n",
       "2               1.142683          0.494231          2.076965   \n",
       "3               1.268431          0.539495          2.071610   \n",
       "4               1.778186          0.027219          1.682292   \n",
       "...                  ...               ...               ...   \n",
       "336016          1.344092          0.450436          2.046958   \n",
       "336017          1.722812          0.267425          2.047756   \n",
       "336018          2.001780         -0.073776          1.723726   \n",
       "336019          1.735124         -0.030038          1.726534   \n",
       "336020          1.509166          0.143271          1.668723   \n",
       "\n",
       "        ft_concept_3_ref  ft_concept_4_ref  month_ref  day_ref  \\\n",
       "0               0.909239         -1.496723          3       25   \n",
       "1               1.384347         -1.729908          1        1   \n",
       "2               0.894240         -1.781902          8       17   \n",
       "3               0.944968         -1.857831          1        1   \n",
       "4               1.705304         -1.974369          1        1   \n",
       "...                  ...               ...        ...      ...   \n",
       "336016          0.945849         -1.890467          2       16   \n",
       "336017          1.266611         -2.208189          5        7   \n",
       "336018          1.916270         -2.156454          1        1   \n",
       "336019          1.620107         -1.920763          1        1   \n",
       "336020          1.422292         -1.786957          3        5   \n",
       "\n",
       "        primary_author_count_ref  total_cited_by_count_per_site_ref  \\\n",
       "0                              4                              933.0   \n",
       "1                              2                            12629.0   \n",
       "2                             24                             3729.0   \n",
       "3                              1                              274.0   \n",
       "4                              3                               51.0   \n",
       "...                          ...                                ...   \n",
       "336016                         1                              176.0   \n",
       "336017                         1                              223.0   \n",
       "336018                         2                                9.0   \n",
       "336019                         1                             1379.0   \n",
       "336020                         3                                1.0   \n",
       "\n",
       "        paper_id_y  \n",
       "0            p3488  \n",
       "1            p4337  \n",
       "2            p1610  \n",
       "3            p3212  \n",
       "4            p1901  \n",
       "...            ...  \n",
       "336016       p2030  \n",
       "336017       p2661  \n",
       "336018       p2517  \n",
       "336019       p2958  \n",
       "336020       p2109  \n",
       "\n",
       "[336021 rows x 216 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testid = test['id']\n",
    "test = test.drop(columns=['id'])\n",
    "\n",
    "# Merge fitur dari 'paper'\n",
    "test = test.merge(numerical_features, left_on='paper', right_on='paper_id', how='left')\n",
    "test = test.rename(columns={col: f'{col}_paper' for col in numerical_feature_names})\n",
    "\n",
    "# Merge fitur dari 'referenced_paper'\n",
    "test = test.merge(numerical_features, left_on='referenced_paper', right_on='paper_id', how='left')\n",
    "test = test.rename(columns={col: f'{col}_ref' for col in numerical_feature_names})\n",
    "\n",
    "# Drop kolom ID hasil merge yang gak dipakai\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping aman\n",
    "test['publish_date_ref'] = test['referenced_paper'].map(pub_date_dict)\n",
    "test['publish_date_paper'] = test['paper'].map(pub_date_dict)\n",
    "\n",
    "# Convert ke datetime\n",
    "test['publish_date_ref'] = pd.to_datetime(test['publish_date_ref'], errors='coerce')\n",
    "test['publish_date_paper'] = pd.to_datetime(test['publish_date_paper'], errors='coerce')\n",
    "\n",
    "# Hitung selisih\n",
    "test['diff_date'] = (test['publish_date_ref'] - test['publish_date_paper']).dt.days\n",
    "test['diff_month'] = test['diff_date'] / 30\n",
    "test['diff_week'] = test['diff_date'] / 7\n",
    "test['diff_exact_year'] = test['diff_date'] / 365\n",
    "\n",
    "test['diff_date'] = test['diff_date'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Doc2Vec Metrics: 100%|██████████| 336021/336021 [05:32<00:00, 1009.66it/s]\n",
      "Calculating Title FastText Metrics: 100%|██████████| 336021/336021 [05:57<00:00, 941.23it/s] \n",
      "Calculating Concept FastText Metrics: 100%|██████████| 336021/336021 [05:48<00:00, 965.20it/s] \n"
     ]
    }
   ],
   "source": [
    "# Doc2Vec calculations\n",
    "doc_cosine_sims = []\n",
    "doc_euclidean_dists = []\n",
    "doc_manhattan_dists = []\n",
    "doc_pearson_corrs = []\n",
    "\n",
    "for i, row in tqdm(test.iterrows(), total=len(test), desc=\"Calculating Doc2Vec Metrics\"):\n",
    "    vec1 = get_doc_vector(row['paper'])\n",
    "    vec2 = get_doc_vector(row['referenced_paper'])\n",
    "    \n",
    "    cosine_sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    doc_cosine_sims.append(cosine_sim)\n",
    "    \n",
    "    euc_dist = euclidean(vec1, vec2)\n",
    "    doc_euclidean_dists.append(euc_dist)\n",
    "    \n",
    "    man_dist = cityblock(vec1, vec2)\n",
    "    doc_manhattan_dists.append(man_dist)\n",
    "    \n",
    "    if np.var(vec1) > 0 and np.var(vec2) > 0:\n",
    "        pearson_corr, _ = pearsonr(vec1, vec2)\n",
    "        doc_pearson_corrs.append(pearson_corr)\n",
    "    else:\n",
    "        doc_pearson_corrs.append(0.0)\n",
    "\n",
    "test['doc2vec_cosine_sim'] = doc_cosine_sims\n",
    "test['doc2vec_euclidean_dist'] = doc_euclidean_dists\n",
    "test['doc2vec_manhattan_dist'] = doc_manhattan_dists\n",
    "test['doc2vec_pearson_corr'] = doc_pearson_corrs\n",
    "\n",
    "# Title FastText calculations\n",
    "title_cosine_sims = []\n",
    "title_euclidean_dists = []\n",
    "title_manhattan_dists = []\n",
    "title_pearson_corrs = []\n",
    "\n",
    "for i, row in tqdm(test.iterrows(), total=len(test), desc=\"Calculating Title FastText Metrics\"):\n",
    "    vec1 = get_title_vector(row['paper'])\n",
    "    vec2 = get_title_vector(row['referenced_paper'])\n",
    "    \n",
    "    cosine_sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    title_cosine_sims.append(cosine_sim)\n",
    "    \n",
    "    euc_dist = euclidean(vec1, vec2)\n",
    "    title_euclidean_dists.append(euc_dist)\n",
    "    \n",
    "    man_dist = cityblock(vec1, vec2)\n",
    "    title_manhattan_dists.append(man_dist)\n",
    "    \n",
    "    if np.var(vec1) > 0 and np.var(vec2) > 0:\n",
    "        pearson_corr, _ = pearsonr(vec1, vec2)\n",
    "        title_pearson_corrs.append(pearson_corr)\n",
    "    else:\n",
    "        title_pearson_corrs.append(0.0)\n",
    "\n",
    "test['title_cosine_sim'] = title_cosine_sims\n",
    "test['title_euclidean_dist'] = title_euclidean_dists\n",
    "test['title_manhattan_dist'] = title_manhattan_dists\n",
    "test['title_pearson_corr'] = title_pearson_corrs\n",
    "\n",
    "# Concept FastText calculations\n",
    "concept_cosine_sims = []\n",
    "concept_euclidean_dists = []\n",
    "concept_manhattan_dists = []\n",
    "concept_pearson_corrs = []\n",
    "\n",
    "for i, row in tqdm(test.iterrows(), total=len(test), desc=\"Calculating Concept FastText Metrics\"):\n",
    "    vec1 = get_concept_vector(row['paper'])\n",
    "    vec2 = get_concept_vector(row['referenced_paper'])\n",
    "    \n",
    "    cosine_sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    concept_cosine_sims.append(cosine_sim)\n",
    "    \n",
    "    euc_dist = euclidean(vec1, vec2)\n",
    "    concept_euclidean_dists.append(euc_dist)\n",
    "    \n",
    "    man_dist = cityblock(vec1, vec2)\n",
    "    concept_manhattan_dists.append(man_dist)\n",
    "    \n",
    "    if np.var(vec1) > 0 and np.var(vec2) > 0:\n",
    "        pearson_corr, _ = pearsonr(vec1, vec2)\n",
    "        concept_pearson_corrs.append(pearson_corr)\n",
    "    else:\n",
    "        concept_pearson_corrs.append(0.0)\n",
    "\n",
    "test['concept_cosine_sim'] = concept_cosine_sims\n",
    "test['concept_euclidean_dist'] = concept_euclidean_dists\n",
    "test['concept_manhattan_dist'] = concept_manhattan_dists\n",
    "test['concept_pearson_corr'] = concept_pearson_corrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SPECTER Metrics: 100%|██████████| 336021/336021 [05:17<00:00, 1059.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import euclidean, cityblock\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Build embedding dictionary\n",
    "specter_embedding_dict = {\n",
    "    row['paper_id']: row[[f'specter_title_{i}' for i in range(768)]].values.astype(np.float32)\n",
    "    for _, row in title_dfz.iterrows()\n",
    "}\n",
    "\n",
    "cosine_sims = []\n",
    "euclidean_dists = []\n",
    "manhattan_dists = []\n",
    "pearson_corrs = []\n",
    "\n",
    "for _, row in tqdm(test.iterrows(), total=len(test), desc=\"SPECTER Metrics\"):\n",
    "    pid1 = row['paper']\n",
    "    pid2 = row['referenced_paper']\n",
    "    \n",
    "    if pid1 in specter_embedding_dict and pid2 in specter_embedding_dict:\n",
    "        vec1 = specter_embedding_dict[pid1]\n",
    "        vec2 = specter_embedding_dict[pid2]\n",
    "\n",
    "        cosine_sims.append(cosine_similarity([vec1], [vec2])[0][0])\n",
    "        euclidean_dists.append(euclidean(vec1, vec2))\n",
    "        manhattan_dists.append(cityblock(vec1, vec2))\n",
    "\n",
    "        try:\n",
    "            pearson_corrs.append(pearsonr(vec1, vec2)[0])\n",
    "        except:\n",
    "            pearson_corrs.append(0.0)\n",
    "    else:\n",
    "        cosine_sims.append(0.0)\n",
    "        euclidean_dists.append(0.0)\n",
    "        manhattan_dists.append(0.0)\n",
    "        pearson_corrs.append(0.0)\n",
    "\n",
    "test['specter_cosine_sim'] = cosine_sims\n",
    "test['specter_euclidean_dist'] = euclidean_dists\n",
    "test['specter_manhattan_dist'] = manhattan_dists\n",
    "test['specter_pearson_corr'] = pearson_corrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SPECTER Metrics: 100%|██████████| 336021/336021 [05:15<00:00, 1066.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import euclidean, cityblock\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Build embedding dictionary\n",
    "specter_embedding_dict = {\n",
    "    row['paper_id']: row[[f'specter_concepts_title_{i}' for i in range(768)]].values.astype(np.float32)\n",
    "    for _, row in concept_dfz.iterrows()\n",
    "}\n",
    "\n",
    "cosine_sims = []\n",
    "euclidean_dists = []\n",
    "manhattan_dists = []\n",
    "pearson_corrs = []\n",
    "\n",
    "for _, row in tqdm(test.iterrows(), total=len(test), desc=\"SPECTER Metrics\"):\n",
    "    pid1 = row['paper']\n",
    "    pid2 = row['referenced_paper']\n",
    "    \n",
    "    if pid1 in specter_embedding_dict and pid2 in specter_embedding_dict:\n",
    "        vec1 = specter_embedding_dict[pid1]\n",
    "        vec2 = specter_embedding_dict[pid2]\n",
    "\n",
    "        cosine_sims.append(cosine_similarity([vec1], [vec2])[0][0])\n",
    "        euclidean_dists.append(euclidean(vec1, vec2))\n",
    "        manhattan_dists.append(cityblock(vec1, vec2))\n",
    "\n",
    "        try:\n",
    "            pearson_corrs.append(pearsonr(vec1, vec2)[0])\n",
    "        except:\n",
    "            pearson_corrs.append(0.0)\n",
    "    else:\n",
    "        cosine_sims.append(0.0)\n",
    "        euclidean_dists.append(0.0)\n",
    "        manhattan_dists.append(0.0)\n",
    "        pearson_corrs.append(0.0)\n",
    "\n",
    "test['specter_cosine_sim_concepts'] = cosine_sims\n",
    "test['specter_euclidean_concepts_dist'] = euclidean_dists\n",
    "test['specter_manhattan_concepts_dist'] = manhattan_dists\n",
    "test['specter_pearson_concepts_corr'] = pearson_corrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating doc2vec Scalar Features: 100%|██████████| 336021/336021 [00:53<00:00, 6318.47it/s]\n",
      "Calculating title Scalar Features: 100%|██████████| 336021/336021 [01:08<00:00, 4896.44it/s]\n",
      "Calculating concept Scalar Features: 100%|██████████| 336021/336021 [01:09<00:00, 4868.22it/s]\n"
     ]
    }
   ],
   "source": [
    "calculate_scalar_vector_features(\n",
    "    test, 'paper', 'referenced_paper', get_doc_vector, prefix='doc2vec'\n",
    ")\n",
    "\n",
    "calculate_scalar_vector_features(\n",
    "    test, 'paper', 'referenced_paper', get_title_vector, prefix='title'\n",
    ")\n",
    "\n",
    "calculate_scalar_vector_features(\n",
    "    test, 'paper', 'referenced_paper', get_concept_vector, prefix='concept'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating doc2vec Divergence Features: 100%|██████████| 336021/336021 [03:15<00:00, 1722.81it/s]\n",
      "Calculating title Divergence Features: 100%|██████████| 336021/336021 [03:13<00:00, 1739.37it/s]\n",
      "Calculating concept Divergence Features: 100%|██████████| 336021/336021 [03:35<00:00, 1558.64it/s]\n"
     ]
    }
   ],
   "source": [
    "calculate_vector_divergence_features(\n",
    "    test, 'paper', 'referenced_paper', get_doc_vector, prefix='doc2vec'\n",
    ")\n",
    "\n",
    "calculate_vector_divergence_features(\n",
    "    test, 'paper', 'referenced_paper', get_doc_vector, prefix='title'\n",
    ")\n",
    "\n",
    "calculate_vector_divergence_features(\n",
    "    test, 'paper', 'referenced_paper', get_title_vector, prefix='concept'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating doc2vec NN-like Features: 100%|██████████| 336021/336021 [00:25<00:00, 13289.10it/s]\n"
     ]
    }
   ],
   "source": [
    "calculate_advanced_vector_features(\n",
    "    test, 'paper', 'referenced_paper', get_doc_vector, prefix='doc2vec'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['now_year_paper'] = 2025 - test['publication_year_paper']\n",
    "test['now_year_ref'] = 2025 - test['publication_year_ref']\n",
    "\n",
    "test['diff_age'] = test['now_year_paper'] - test['now_year_ref']\n",
    "test['ratio_age'] = test['now_year_ref'] / (test['now_year_paper'] + 1e-5)\n",
    "\n",
    "test['citation_diff'] = test['cited_by_count_paper'] - test['cited_by_count_ref']\n",
    "test['citation_ratio'] = test['cited_by_count_ref'] / (test['cited_by_count_paper'] + 1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colz = list(X.columns)\n",
    "test2 = test[colz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model2.predict_proba(test2.select_dtypes(include='number'))[:, 1]\n",
    "pred = (pred >= 0.1189).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_referenced\n",
       "0    332492\n",
       "1      3529\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame({\n",
    "    'id':testid,\n",
    "    'is_referenced':pred\n",
    "})\n",
    "\n",
    "sub['is_referenced'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save_model(\"DV2058.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission-cb-Doc2V0585.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7137938,
     "sourceId": 11397185,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
